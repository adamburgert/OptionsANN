


pip install openpyxl parameter


import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import itertools
from tqdm import tqdm
from torch.optim.lr_scheduler import ReduceLROnPlateau
from sklearn.model_selection import ParameterGrid
from sklearn.metrics import mean_squared_error
from torch.utils.data import TensorDataset, DataLoader
import random
from torch.cuda.amp import autocast, GradScaler
from itertools import product


# Load data
Data_for_Put_options = pd.read_excel('train_gld_before_2016.xlsx', sheet_name='GLD_PUT')

batch_size = 2048

# Extract date and volatility information
exp_dates_for_Put = Data_for_Put_options['Exp Date = T']
dates_for_Put = Data_for_Put_options['T - 5']
volas_for_Put_percent = Data_for_Put_options['21_Day_Percent_Volatility']
volas_for_Put_nominal = Data_for_Put_options['21_Day_Volatility']

dates_for_Put = Data_for_Put_options['T - 5']
Data_for_Put_options = Data_for_Put_options.drop(columns=['T - 5', 'Exp Date = T'])

Features_for_Put_options = Data_for_Put_options[['ETF Price on T - 5', 'Strike_1', 'Strike_2', 'Strike_3', 'Strike_4', 'Strike_5','21_Day_Percent_Volatility', '21_Day_Volatility']]
Data_Target_Put = Data_for_Put_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]
Close_prices_Put = Data_for_Put_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]

Features_for_Put_options['ETF Price on T - 5'] = pd.to_numeric(Features_for_Put_options['ETF Price on T - 5'], errors='coerce')
Features_for_Put_options = Features_for_Put_options.dropna(subset=['ETF Price on T - 5'])
Close_prices_Put = Close_prices_Put.loc[Features_for_Put_options.index]

# Set seed and device
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

import random
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler
from torch.utils.data import DataLoader, TensorDataset
import numpy as np

# Define model architecture
class MultiOutputOptionsPricingANN(nn.Module):
    def __init__(self, input_dim, output_dim, neurons_per_layer):
        super(MultiOutputOptionsPricingANN, self).__init__()
        layers = [nn.Linear(input_dim, neurons_per_layer[0]), nn.BatchNorm1d(neurons_per_layer[0]), nn.ReLU()]
        for i in range(1, len(neurons_per_layer)):
            layers += [nn.Linear(neurons_per_layer[i-1], neurons_per_layer[i]), nn.BatchNorm1d(neurons_per_layer[i]), nn.ReLU()]
        layers.append(nn.Linear(neurons_per_layer[-1], output_dim))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

# Fixed neuron options and learning rates
neuron_options = [50, 150, 500, 800, 1000, 1250, 1500, 3500,6000, 7000]
Learning_Rates = [0.00001,0.0001,0.001,0.01,0.1]

# Define the number of random trials
num_trials = 50
# Define the number of random trials to run

# Data preparation
Features_for_Put_tensor = torch.tensor(Features_for_Put_options.values, dtype=torch.float32).to(device)
Data_Target_Put_tensor = torch.tensor(Data_Target_Put.values, dtype=torch.float32).to(device)
Put_dataset = TensorDataset(Features_for_Put_tensor, Data_Target_Put_tensor)
Put_loader = DataLoader(Put_dataset, batch_size=2048, shuffle=True)

# Track the best configuration and model
best_val_loss = float('inf')
best_config = None
best_model_state = None
best_epoch_Put = None
Best_Learning_rate_Put = None



# Random search loop
for trial in range(num_trials):
    # Randomly select learning rate
    lr = random.choice(Learning_Rates)

    # Randomly select neuron configuration for each layer
    neurons = [random.choice(neuron_options) for _ in range(8)]

    # Initialize model, optimizer, and loss function
    model = MultiOutputOptionsPricingANN(Features_for_Put_tensor.shape[1], 5, neurons).to(device)
    optimizer = optim.SGD(model.parameters(), lr=lr)
    criterion = nn.MSELoss()
    scaler = torch.amp.GradScaler('cuda')

    # Early stopping setup
    patience = 50
    max_epochs = 2000
    epochs_no_improve = 0
    best_loss_current = float('inf')

    for epoch in range(max_epochs):
        model.train()
        for features_batch, targets_batch in Put_loader:
            optimizer.zero_grad()
            with torch.amp.autocast('cuda'):  # Enable mixed precision
                predictions = model(features_batch.to(device))
                loss = criterion(predictions, targets_batch.to(device))
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

        # Validation step
        model.eval()
        with torch.no_grad():
            val_predictions = model(Features_for_Put_tensor).cpu().numpy()
            val_loss = np.mean((val_predictions - Data_Target_Put_tensor.cpu().numpy()) ** 2)

        # Track best model and apply early stopping
        if val_loss < best_loss_current:
            best_loss_current = val_loss
            epochs_no_improve = 0
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                best_config = (lr, neurons)
                best_epoch_Put = epoch + 1
                Best_Learning_rate_Put = lr
                best_model_state = model.state_dict()  # Save model state
        else:
            epochs_no_improve += 1

        if epochs_no_improve >= patience:
            print(f"Early stopping at epoch {epoch+1} for trial {trial+1} with neurons {neurons}, val loss {val_loss:.6f}")
            break

    print(f"Trial {trial+1}/{num_trials}: LR={lr}, Neurons={neurons}, Best Loss {best_loss_current:.6f}")
    torch.cuda.reset_peak_memory_stats()  # Reset VRAM tracking

# Save the best model after the random search
if best_model_state:
    # Initialize a model to load the best state dictionary
    best_model = MultiOutputOptionsPricingANN(Features_for_Put_tensor.shape[1], 5, best_config[1]).to(device)
    best_model.load_state_dict(best_model_state)
    torch.save(best_model_state, './training_results/best_random_search_model.pth')
    print(f"Best model saved with config {best_config}, Best Validation Loss={best_val_loss:.6f}")

    # Generate predictions using the best model
    best_model.eval()
    with torch.no_grad():
        train_predictions_Put = best_model(Features_for_Put_tensor).cpu().numpy()

    # You can now use `train_predictions_Put` for further evaluation or analysis
    print(f"Final training predictions: {train_predictions_Put[:5]}")  # Print first 5 predictions for inspection


    # Calculate overall MSE, MAE, and MAPE across all strikes
    def calculate_overall_metrics(true_values, predicted_values):
        mse = mean_squared_error(true_values, predicted_values)
        mae = np.mean(np.abs(true_values - predicted_values))
        mape = np.mean(np.abs((true_values - predicted_values) / true_values)) * 100
        return mse, mae, mape

    overall_mse, overall_mae, overall_mape = calculate_overall_metrics(Close_prices_Put.values, train_predictions_Put)

    # Calculate prediction difference for each strike (Actual - Predicted)
    prediction_differences = {
        f'Strike_{i} Diff': Data_for_Put_options[f'Close_{i}'].values - train_predictions_Put[:, i-1]
        for i in range(1, 6)
    }

    # Calculate average price prediction difference across all strikes
    avg_prediction_diff = np.mean(np.abs(Data_for_Put_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']].values - train_predictions_Put), axis=1)
    avg_price_diff = np.mean(avg_prediction_diff)

   # Check that all arrays have the same length
assert len(Features_for_Put_options['Strike_1']) == len(Data_for_Put_options['Close_1']) == len(train_predictions_Put), \
    "Mismatch in array lengths for strike, close, and prediction data."

# Ensure the prediction differences also have the correct length
assert len(avg_prediction_diff) == len(Features_for_Put_options), "Mismatch in array length between prediction diff and other features."

# Ensure all arrays/lists are of the same length
num_rows = len(Features_for_Put_options)

# Create the DataFrame with consistent column lengths
Res_Put_options = pd.DataFrame({
    'Exp Date = T': exp_dates_for_Put,
    'T - 5': dates_for_Put,
    '21_Day_Percent_Volatility': volas_for_Put_percent,
    '21_Day_Volatility': volas_for_Put_nominal,
    'Strike_1': Features_for_Put_options['Strike_1'].values,
    'Close_1': Data_for_Put_options['Close_1'].values,
    'Predicted Price_1': train_predictions_Put[:, 0],
    'MSE_1': [overall_mse] * num_rows,
    'MAE_1': [overall_mae] * num_rows,
    'MAPE_1': [overall_mape] * num_rows,
    'Strike_2': Features_for_Put_options['Strike_2'].values,
    'Close_2': Data_for_Put_options['Close_2'].values,
    'Predicted Price_2': train_predictions_Put[:, 1],
    'MSE_2': [overall_mse] * num_rows,
    'MAE_2': [overall_mae] * num_rows,
    'MAPE_2': [overall_mape] * num_rows,
    'Strike_3': Features_for_Put_options['Strike_3'].values,
    'Close_3': Data_for_Put_options['Close_3'].values,
    'Predicted Price_3': train_predictions_Put[:, 2],
    'MSE_3': [overall_mse] * num_rows,
    'MAE_3': [overall_mae] * num_rows,
    'MAPE_3': [overall_mape] * num_rows,
    'Strike_4': Features_for_Put_options['Strike_4'].values,
    'Close_4': Data_for_Put_options['Close_4'].values,
    'Predicted Price_4': train_predictions_Put[:, 3],
    'MSE_4': [overall_mse] * num_rows,
    'MAE_4': [overall_mae] * num_rows,
    'MAPE_4': [overall_mape] * num_rows,
    'Strike_5': Features_for_Put_options['Strike_5'].values,
    'Close_5': Data_for_Put_options['Close_5'].values,
    'Predicted Price_5': train_predictions_Put[:, 4],
    'MSE_5': [overall_mse] * num_rows,
    'MAE_5': [overall_mae] * num_rows,
    'MAPE_5': [overall_mape] * num_rows,
    'Seed': [seed] * num_rows,
    'Best Epoch': [best_epoch_Put] * num_rows,
    'Learning Rate': [Best_Learning_rate_Put] * num_rows,
    'Num Neurons': [neurons] * num_rows,
    'Epochs': [best_epoch_Put] * num_rows,
    'Overall MSE': [overall_mse] * num_rows,
    'Overall MAE': [overall_mae] * num_rows,
    'Overall MAPE': [overall_mape] * num_rows,
    **{k: v[:num_rows] for k, v in prediction_differences.items()},  # Truncate if necessary
    'Average Price Prediction Diff': [avg_price_diff] * num_rows  # Match length of DataFrame
})


for i in range(1, 6):
    # Calculate the difference between predicted and actual close prices
    Res_Put_options[f'Price Prediction Difference_{i}'] = Res_Put_options[f'Predicted Price_{i}'] - Res_Put_options[f'Close_{i}']

    # Calculate the percentage difference
    Res_Put_options[f'Price Prediction Difference in percentage_{i}'] = (
        Res_Put_options[f'Price Prediction Difference_{i}'] / Res_Put_options[f'Close_{i}'] * 100
    )

# Average Price Prediction Difference calculations for each strike
Res_Put_options['Average Price Prediction Difference'] = Res_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Average Price Prediction Difference in percentage calculations for each strike
Res_Put_options['Average Price Prediction Difference in percentage'] = Res_Put_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference across all strikes
Res_Put_options['Overall Average Price Prediction Difference'] = Res_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference in percentage across all strikes
Res_Put_options['Overall Average Price Prediction Difference in percentage'] = Res_Put_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

 # Assign MAPE for each strike

# Calculate overall performance metrics based on close prices
MSE_Put = ((Res_Put_options[[f'Close_{i}' for i in range(1, 6)]].values -
              Res_Put_options[[f'Predicted Price_{i}' for i in range(1, 6)]].values) ** 2).mean().mean()
MAE_Put = (abs(Res_Put_options[[f'Close_{i}' for i in range(1, 6)]].values -
             Res_Put_options[[f'Predicted Price_{i}' for i in range(1, 6)]].values)).mean().mean()
MAPE_Put = (100 * abs((Res_Put_options[[f'Close_{i}' for i in range(1, 6)]].values -
               Res_Put_options[[f'Predicted Price_{i}' for i in range(1, 6)]].values) /
               Res_Put_options[[f'Close_{i}' for i in range(1, 6)]].values)).mean().mean()

# Assign overall model performance metrics to all rows
Res_Put_options['MSE'] = [MSE_Put] * len(Res_Put_options)  # Overall MSE based on close prices
Res_Put_options['MAE'] = [MAE_Put] * len(Res_Put_options)  # Overall MAE based on close prices
Res_Put_options['MAPE'] = [MAPE_Put] * len(Res_Put_options)  # Overall MAPE based on close prices


# Print the DataFrame and metrics for verification
print(Res_Put_options.head())
print(f'MSE: {MSE_Put}, MAE: {MAE_Put}, MAPE: {MAPE_Put}')

# Calculate the metrics for each strike price's close prediction for Puts
MSE_Put, MAE_Put, MAPE_Put = calculate_overall_metrics(Close_prices_Put.values, train_predictions_Put)

#Res_Put_options['Weight decay'] = weight_decay
Res_Put_options['Learning rate'] = lr
#Res_Put_options['Dropout rate'] = dropout
Res_Put_options['Epoch size'] = best_epoch_Put
Res_Put_options['Random seed'] = seed






# Display the final DataFrame for Puts with the new metrics columns
print(Res_Put_options.head())



    # Save results to CSV
Res_Put_options.to_csv('./training_results/Res_Put_options_random_search_without_volatility_input_150-3500.csv', index=False)

print("Results saved to './training_results/Res_Put_options.csv'.")



import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt

# Load testing data
testing_Data_for_Put_options = pd.read_excel('test_gld_after_2016.xlsx', sheet_name='GLD_PUT')
test_volas_for_Put_percent = testing_Data_for_Put_options['21_Day_Percent_Volatility']
test_volas_for_Put_nominal = testing_Data_for_Put_options['21_Day_Volatility']

# Clean column names
testing_Data_for_Put_options.columns = testing_Data_for_Put_options.columns.str.strip()

# Prepare features and targets for Put options
testing_Features_for_Put_options = testing_Data_for_Put_options[['ETF Price on T - 5', 'Strike_1', 'Strike_2', 'Strike_3', 'Strike_4', 'Strike_5','21_Day_Percent_Volatility','21_Day_Volatility']].copy()
testing_Data_Target_Put = testing_Data_for_Put_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]

# Convert columns to numeric
testing_Features_for_Put_options['ETF Price on T - 5'] = pd.to_numeric(testing_Features_for_Put_options['ETF Price on T - 5'], errors='coerce')

# Drop rows with missing values in the feature set
testing_Features_for_Put_options = testing_Features_for_Put_options.dropna(subset=['ETF Price on T - 5'])

# Ensure the target aligns with the filtered features
test_Close_prices_Put = testing_Data_Target_Put.loc[testing_Features_for_Put_options.index]

# Get test dates and volatility
test_dates_for_Put = testing_Data_for_Put_options['T - 5']
exp_dates_for_Put_test = testing_Data_for_Put_options['Exp Date = T']

# Drop 'Exp Date = T' column for scaling and prediction
testing_Data_for_Put_options = testing_Data_for_Put_options.drop(columns=['Exp Date = T'])

# Check if CUDA is available and set the device (reuse if defined previously)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Tensor conversion for testing features and targets, with CUDA support
Put_features_tensor_test = torch.tensor(testing_Features_for_Put_options.values, dtype=torch.float32).to(device)
Put_target_tensor_test = torch.tensor(testing_Data_Target_Put.values, dtype=torch.float32).to(device)

# Define input features and output strikes based on your dataset
input_features = 8  # Number of features in your testing data (e.g., ETF Price, Strike prices, Volatility, etc.)
output_strikes = 5  # Number of strike prices you're predicting (Close_1, Close_2, ..., Close_5)

# Check if CUDA is available and set the device (reuse if defined previously)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")



# Assuming `best_config` is a tuple containing (learning_rate, neuron configuration)
if best_model_state:
    # Retrieve the best neuron configuration
    _, best_neurons = best_config

    # Initialize a model with the exact configuration from the best random search trial
    best_model = MultiOutputOptionsPricingANN(Features_for_Put_tensor.shape[1], 5, best_neurons).to(device)
    best_model.load_state_dict(best_model_state)  # Load the saved state dict

    # Save the best model's state dict
    torch.save(best_model_state, './training_results/best_random_search_model.pth')
    print(f"Best model saved with config {best_config}, Best Validation Loss={best_val_loss:.6f}")

    # Generate predictions using the best model
    best_model.eval()
    with torch.no_grad():
        train_predictions_Put = best_model(Features_for_Put_tensor).cpu().numpy()

    # Print first 5 predictions for inspection
    print(f"Final training predictions: {train_predictions_Put[:5]}")



# Make predictions with the loaded Put options model
with torch.no_grad():  # Disable gradient calculation
    test_predictions_Put = best_model(Put_features_tensor_test)

# Move predictions back to CPU and convert to numpy for further processing if needed
test_predictions_Put = test_predictions_Put.cpu().numpy()

# Ensure both actual and predicted arrays have the same shape
assert Put_target_tensor_test.shape == test_predictions_Put.shape, "Shape mismatch between actual and predicted prices."

# Function to calculate metrics
def Metrics(actual, predicted):
    MSE_test_Put = np.mean((actual - predicted) ** 2, axis=0)  # MSE for each strike
    MAE_test_Put = np.mean(np.abs(actual - predicted), axis=0)  # MAE for each strike
    MAPE_test_Put = np.mean(np.abs((actual - predicted) / (actual + 1e-8)), axis=0) * 100  # MAPE for each strike, avoid division by zero

    return MSE_test_Put, MAE_test_Put, MAPE_test_Put

# Calculate metrics for each Put option
MSE_test_Put, MAE_test_Put, MAPE_test_Put = Metrics(test_Close_prices_Put.values, test_predictions_Put)

# Print each metric for each close price in Puts
for i in range(len(MSE_test_Put)):
    print(f'Put Options Price_{i+1} - Strike_{i+1}: MSE (testing): {MSE_test_Put[i]:.4f}, MAE (testing): {MAE_test_Put[i]:.4f}, MAPE (testing): {MAPE_test_Put[i]:.2f}%')

# Create the Test_Put_options DataFrame
Test_Put_options = pd.DataFrame({
    'Exp Date = T': exp_dates_for_Put_test,
    'T - 5': test_dates_for_Put,
    '21_Day_Percent_Volatility': test_volas_for_Put_percent,
    '21_Day_Volatility': test_volas_for_Put_nominal,
    'ETF Price on T - 5': testing_Features_for_Put_options['ETF Price on T - 5'].values,
})

# Add strike prices and predictions to the DataFrame
for i in range(1, 6):  # Assuming there are 5 strike prices
    Test_Put_options[f'Strike_{i}'] = testing_Features_for_Put_options[f'Strike_{i}'].values
    Test_Put_options[f'Close_{i}'] = testing_Data_Target_Put[f'Close_{i}'].values  # Actual close prices
    Test_Put_options[f'Predicted Price_{i}'] = test_predictions_Put[:, i - 1]  # Predicted prices

# Calculate the prediction differences and percentage differences for each strike
for i in range(1, 6):
    # Calculate the difference between predicted and actual close prices
    Test_Put_options[f'Price Prediction Difference_{i}'] = Test_Put_options[f'Predicted Price_{i}'] - Test_Put_options[f'Close_{i}']

    # Calculate the percentage difference
    Test_Put_options[f'Price Prediction Difference in percentage_{i}'] = (
        Test_Put_options[f'Price Prediction Difference_{i}'] / Test_Put_options[f'Close_{i}'].replace(0, np.nan) * 100
    )

# Calculate average price prediction differences
Test_Put_options['Average Price Prediction Difference'] = Test_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

Test_Put_options['Average Price Prediction Difference in percentage'] = Test_Put_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference across all strikes
Test_Put_options['Overall Average Price Prediction Difference'] = Test_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference in percentage across all strikes
Test_Put_options['Overall Average Price Prediction Difference in percentage'] = Test_Put_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create a DataFrame with metrics for each strike price
metrics_df = pd.DataFrame({
    'Strike': [f'Strike_{i+1} Close_{i+1}' for i in range(len(MSE_test_Put))],
    'MSE_test_Put_close': MSE_test_Put,
    'MAE_test_Put_close': MAE_test_Put,
    'MAPE_test_Put_Close': MAPE_test_Put,
})

# Assign overall model performance metrics to all rows
Test_Put_options['MSE'] = np.mean(MSE_test_Put)  # Overall MSE based on close prices
Test_Put_options['MAE'] = np.mean(MAE_test_Put)  # Overall MAE based on close prices
Test_Put_options ['MAPE'] = np.mean(MAPE_test_Put)
Test_Put_options['Learning rate'] = lr  # Assuming you define this in your hyperparameter optimization
Test_Put_options['Epoch size'] = best_epoch_Put  # Likewiseest_Put_options['MAPE'] = np.mean(MAPE_test_Put)  # Overall MAPE based on close prices


# Print the DataFrame and metrics for verification
print(Test_Put_options.head())
print(f'MSE: {np.mean(MSE_test_Put):.4f}, MAE: {np.mean(MAE_test_Put):.4f}, MAPE: {np.mean(MAPE_test_Put):.2f}%')

# Combine the metrics with the main DataFrame
Test_Put_options = pd.concat([Test_Put_options, metrics_df], axis=1)

# Save results to Excel
with pd.ExcelWriter('./testing_results/GLD_testing_results_with_ANN_Adam_random_search_Testing_without_volatility_input_Puts_.xlsx') as writer:
    Test_Put_options.to_excel(writer, sheet_name='Put_Options', index=False)

# Display the final DataFrame for verification
print(Test_Put_options.head())






# Define the strike prices to plot
strikes = [1, 2, 3, 4, 5]  # Corresponding to Close price_1 to Close price_5

# Create a plot for Actual vs Predicted Close Prices for each strike
for strike in strikes:
    plt.figure(figsize=(12, 6))

    # Plot actual close prices
    plt.plot(range(len(Res_Put_options)), Res_Put_options[f'Close_{strike}'],
             label=f'Actual Close Price Close_{strike} (Strike_{strike})', color='blue', marker='o', linestyle='-')

    # Plot predicted close prices
    plt.plot(range(len(Res_Put_options)), Res_Put_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price Close_{strike} (Strike_{strike})', color='red', marker='x', linestyle='--')

    # Add labels and title
    plt.xlabel('Day')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs Predicted Close Prices using ANN+Random-Search for Close_{strike} (without volatility Input) ANN 8 layers Training dataset', fontsize=10)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot
    plt.savefig(f'./training_results/Actual_vs_Predicted_ANN_randomSearch_Strike_{strike}_Close_{strike}_Volatility_Input.png')
    plt.show()


# Create scatter plots for residuals for each strike level
for strike in strikes:
    plt.figure(figsize=(14, 6))
    plt.scatter(Res_Put_options.index, Res_Put_options[f'Price Prediction Difference_{strike}'], color='purple', alpha=0.5)
    plt.axhline(0, color='red', linestyle='--', linewidth=1)
    plt.xlabel('Day')
    plt.ylabel(f'Price Prediction Difference (Strike_{strike}) in USD$')
    plt.title(f'Residuals for Close Price_{strike} Close Prices (ANN+Random-Search) (without volatility Input) ANN 8 layers Training dataset', fontsize=12)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the residuals plot
    plt.savefig(f'./training_results/Residuals_Put_Options_ANN_randomSearch_Strike_{strike}_Volatility_Input.png')
    plt.show()

# Create a scatter plot for actual vs. predicted close prices for each strike
plt.figure(figsize=(10, 6))
for strike in strikes:
    plt.scatter(Res_Put_options[f'Close_{strike}'], Res_Put_options[f'Predicted Price_{strike}'],
                label=f'Strike_{strike} Close_{strike}', alpha=0.5)

# Add a line of perfect prediction for reference
min_price = Res_Put_options[[f'Close_{s}' for s in strikes]].min().min()
max_price = Res_Put_options[[f'Close_{s}' for s in strikes]].max().max()
plt.plot([min_price, max_price], [min_price, max_price], color='red', linewidth=2, linestyle='--', label='Perfect Prediction Line')

# Label the scatter plot
plt.xlabel('Actual Close Price in USD$')
plt.ylabel('Predicted Close Price in USD$')
plt.title('Actual vs Predicted Close Prices using ANN+Random-Search (without volatility Input) ANN 8 layers Training dataset', fontsize=10)
plt.legend()
plt.grid(True)

# Save and show the scatter plot
plt.savefig('./training_results/Actual_vs_Predicted_ANN_randomSearch_Scatter_Volatility_Input.png')
plt.show()

# Plot actual and predicted close prices over time for each strike
plt.figure(figsize=(12, 6))

for strike in strikes:
    plt.figure(figsize=(10, 6))  # Create a new figure for each strike
    plt.plot(dates_for_Put, Res_Put_options[f'Close_{strike}'],
             label=f'Actual Close Price Strike_{strike}', marker='o', color='blue')
    plt.plot(dates_for_Put, Res_Put_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price Strike_{strike}', linestyle='--', marker='x', color='red')

    plt.xlabel('T - 5 Time years')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs. Predicted Close prices using ANN+Random_Search for Close_{strike} Over Time (without volatility Input) ANN 8 layers Training dataset', fontsize=10)
    plt.xticks(rotation=45)  # Rotate date labels for better readability
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot for each strike
    plt.savefig(f'./training_results/Actual_vs_Predicted_ANN_randomSearch_Strike_{strike}_Over_Time_Volatility_Input.png')
    plt.show()

# Set up the figure for the plots
plt.figure(figsize=(14, 10))

# Plotting Average Price Prediction Difference
plt.subplot(2, 1, 1)
plt.plot(Res_Put_options['T - 5'], Res_Put_options['Overall Average Price Prediction Difference'],
         marker='o', linestyle='-', color='blue')
plt.xlabel('T - 5 Time years')
plt.ylabel('Average Price Prediction Difference in USD$')
plt.title('Overall Average Price Prediction Difference using ANN+Random-Search for Put Options (without volatility Input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)

# Plotting Average Price Prediction Difference in Percentage
plt.subplot(2, 1, 2)
plt.plot(Res_Put_options['T - 5'], Res_Put_options['Overall Average Price Prediction Difference in percentage'],
         marker='o', linestyle='-', color='orange')
plt.xlabel('T - 5 Time years')
plt.ylabel('Average Price Prediction Difference in Percentage (%)')
plt.title('Average Price Prediction Difference in Percentage using ANN+Random-Search for Put Options (without volatility Input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)

# Adjust layout
plt.tight_layout()

# Save the figure
plt.savefig('./training_results/Overall_Price_Prediction_Differences_ANN_randomSearch_Volatility_Input.png')

# Show the plots
plt.show()

# Create histograms of prediction differences for each strike
for strike in strikes:
    plt.figure(figsize=(12, 6))
    plt.hist(Res_Put_options[f'Price Prediction Difference_{strike}'], bins=30, color='green', alpha=0.7)
    plt.xlabel(f'Close_{strike} Price Prediction Difference in USD$ (Close Price_{strike}) ')
    plt.ylabel('Frequency')
    plt.title(f'Histogram of Close Price Prediction Differences for Close Price_{strike} using ANN + random Search without volatility Input', fontsize=10)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the histogram
    plt.savefig(f'./training_results/Prediction_Differences_Histogram_Strike_{strike}_ANN_randomSearch_Volatility_Input.png')
    plt.show()



# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_Histogram_Overall_ANN_randomSearch_Volatility_Input.png')
plt.show()


# Add overall price prediction difference column
Res_Put_options['Overall Price Prediction Difference'] = Res_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences
plt.figure(figsize=(12, 6))
plt.hist(Res_Put_options['Overall Price Prediction Difference'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference in USD$')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences for GLD ETF Put Options\nANN+Random Search (without volatility Input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()

# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_Histogram_Put_Options_Overall_ANN_with_random_Search.png')
plt.show()

# Add overall price prediction difference column for percentage
Res_Put_options['Overall Price Prediction Difference in percentage'] = Res_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences in percentage
plt.figure(figsize=(12, 6))
plt.hist(Res_Put_options['Overall Price Prediction Difference in percentage'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference %')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences in Percentage for GLD ETF Put Options\nANN+Random Search (without volatility Input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()



# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_in_Percentage_Histogram_Overall_ANN_randomSearch_Volatility_Input.png')
plt.show()






import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt

# Load testing data
testing_Data_for_Put_options = pd.read_excel('test_gld_after_2016.xlsx', sheet_name='GLD_PUT')
test_volas_for_Put_percent = testing_Data_for_Put_options['21_Day_Percent_Volatility']
test_volas_for_Put_nominal = testing_Data_for_Put_options['21_Day_Volatility']

# Clean column names
testing_Data_for_Put_options.columns = testing_Data_for_Put_options.columns.str.strip()

# Prepare features and targets for Put options
testing_Features_for_Put_options = testing_Data_for_Put_options[['ETF Price on T - 5', 'Strike_1', 'Strike_2', 'Strike_3', 'Strike_4', 'Strike_5']].copy()
testing_Data_Target_Put = testing_Data_for_Put_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]

# Convert columns to numeric
testing_Features_for_Put_options['ETF Price on T - 5'] = pd.to_numeric(testing_Features_for_Put_options['ETF Price on T - 5'], errors='coerce')

# Drop rows with missing values in the feature set
testing_Features_for_Put_options = testing_Features_for_Put_options.dropna(subset=['ETF Price on T - 5'])

# Ensure the target aligns with the filtered features
test_Close_prices_Put = testing_Data_Target_Put.loc[testing_Features_for_Put_options.index]

# Get test dates and volatility
test_dates_for_Put = testing_Data_for_Put_options['T - 5']
exp_dates_for_Put_test = testing_Data_for_Put_options['Exp Date = T']

# Drop 'Exp Date = T' column for scaling and prediction
testing_Data_for_Put_options = testing_Data_for_Put_options.drop(columns=['Exp Date = T'])

# Check if CUDA is available and set the device (reuse if defined previously)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Tensor conversion for testing features and targets, with CUDA support
Put_features_tensor_test = torch.tensor(testing_Features_for_Put_options.values, dtype=torch.float32).to(device)
Put_target_tensor_test = torch.tensor(testing_Data_Target_Put.values, dtype=torch.float32).to(device)

# Define input features and output strikes based on your dataset
input_features = 8  # Number of features in your testing data (e.g., ETF Price, Strike prices, Volatility, etc.)
output_strikes = 5  # Number of strike prices you're predicting (Close_1, Close_2, ..., Close_5)

# Check if CUDA is available and set the device (reuse if defined previously)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")



# Assuming `best_config` is a tuple containing (learning_rate, neuron configuration)
if best_model_state:
    # Retrieve the best neuron configuration
    _, best_neurons = best_config

    # Initialize a model with the exact configuration from the best random search trial
    best_model = MultiOutputOptionsPricingANN(Features_for_Put_tensor.shape[1], 5, best_neurons).to(device)
    best_model.load_state_dict(best_model_state)  # Load the saved state dict

    # Save the best model's state dict
    torch.save(best_model_state, './training_results/best_random_search_model.pth')
    print(f"Best model saved with config {best_config}, Best Validation Loss={best_val_loss:.6f}")

    # Generate predictions using the best model
    best_model.eval()
    with torch.no_grad():
        train_predictions_Put = best_model(Features_for_Put_tensor).cpu().numpy()

    # Print first 5 predictions for inspection
    print(f"Final training predictions: {train_predictions_Put[:5]}")



# Make predictions with the loaded Put options model
with torch.no_grad():  # Disable gradient calculation
    test_predictions_Put = best_model(Put_features_tensor_test)

# Move predictions back to CPU and convert to numpy for further processing if needed
test_predictions_Put = test_predictions_Put.cpu().numpy()

# Ensure both actual and predicted arrays have the same shape
assert Put_target_tensor_test.shape == test_predictions_Put.shape, "Shape mismatch between actual and predicted prices."

# Function to calculate metrics
def Metrics(actual, predicted):
    MSE_test_Put = np.mean((actual - predicted) ** 2, axis=0)  # MSE for each strike
    MAE_test_Put = np.mean(np.abs(actual - predicted), axis=0)  # MAE for each strike
    MAPE_test_Put = np.mean(np.abs((actual - predicted) / (actual + 1e-8)), axis=0) * 100  # MAPE for each strike, avoid division by zero

    return MSE_test_Put, MAE_test_Put, MAPE_test_Put

# Calculate metrics for each Put option
MSE_test_Put, MAE_test_Put, MAPE_test_Put = Metrics(test_Close_prices_Put.values, test_predictions_Put)

# Print each metric for each close price in Puts
for i in range(len(MSE_test_Put)):
    print(f'Put Options Price_{i+1} - Strike_{i+1}: MSE (testing): {MSE_test_Put[i]:.4f}, MAE (testing): {MAE_test_Put[i]:.4f}, MAPE (testing): {MAPE_test_Put[i]:.2f}%')

# Create the Test_Put_options DataFrame
Test_Put_options = pd.DataFrame({
    'Exp Date = T': exp_dates_for_Put_test,
    'T - 5': test_dates_for_Put,
    '21_Day_Percent_Volatility': test_volas_for_Put_percent,
    '21_Day_Volatility': test_volas_for_Put_nominal,
    'ETF Price on T - 5': testing_Features_for_Put_options['ETF Price on T - 5'].values,
})

# Add strike prices and predictions to the DataFrame
for i in range(1, 6):  # Assuming there are 5 strike prices
    Test_Put_options[f'Strike_{i}'] = testing_Features_for_Put_options[f'Strike_{i}'].values
    Test_Put_options[f'Close_{i}'] = testing_Data_Target_Put[f'Close_{i}'].values  # Actual close prices
    Test_Put_options[f'Predicted Price_{i}'] = test_predictions_Put[:, i - 1]  # Predicted prices

# Calculate the prediction differences and percentage differences for each strike
for i in range(1, 6):
    # Calculate the difference between predicted and actual close prices
    Test_Put_options[f'Price Prediction Difference_{i}'] = Test_Put_options[f'Predicted Price_{i}'] - Test_Put_options[f'Close_{i}']

    # Calculate the percentage difference
    Test_Put_options[f'Price Prediction Difference in percentage_{i}'] = (
        Test_Put_options[f'Price Prediction Difference_{i}'] / Test_Put_options[f'Close_{i}'].replace(0, np.nan) * 100
    )

# Calculate average price prediction differences
Test_Put_options['Average Price Prediction Difference'] = Test_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

Test_Put_options['Average Price Prediction Difference in percentage'] = Test_Put_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference across all strikes
Test_Put_options['Overall Average Price Prediction Difference'] = Test_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference in percentage across all strikes
Test_Put_options['Overall Average Price Prediction Difference in percentage'] = Test_Put_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create a DataFrame with metrics for each strike price
metrics_df = pd.DataFrame({
    'Strike': [f'Strike_{i+1} Close_{i+1}' for i in range(len(MSE_test_Put))],
    'MSE_test_Put_close': MSE_test_Put,
    'MAE_test_Put_close': MAE_test_Put,
    'MAPE_test_Put_Close': MAPE_test_Put,
})

# Assign overall model performance metrics to all rows
Test_Put_options['MSE'] = np.mean(MSE_test_Put)  # Overall MSE based on close prices
Test_Put_options['MAE'] = np.mean(MAE_test_Put)  # Overall MAE based on close prices
Test_Put_options ['MAPE'] = np.mean(MAPE_test_Put)
Test_Put_options['Learning rate'] = lr  # Assuming you define this in your hyperparameter optimization
Test_Put_options['Epoch size'] = best_epoch_Put  # Likewiseest_Put_options['MAPE'] = np.mean(MAPE_test_Put)  # Overall MAPE based on close prices


# Print the DataFrame and metrics for verification
print(Test_Put_options.head())
print(f'MSE: {np.mean(MSE_test_Put):.4f}, MAE: {np.mean(MAE_test_Put):.4f}, MAPE: {np.mean(MAPE_test_Put):.2f}%')

# Combine the metrics with the main DataFrame
Test_Put_options = pd.concat([Test_Put_options, metrics_df], axis=1)

# Save results to Excel
with pd.ExcelWriter('./testing_results/GLD_testing_results_with_ANN_Adam_random_search_Testing_without_volatility_input_Puts_.xlsx') as writer:
    Test_Put_options.to_excel(writer, sheet_name='Put_Options', index=False)

# Display the final DataFrame for verification
print(Test_Put_options.head())








# Define the strike prices to plot
strikes_test = [1, 2, 3, 4, 5]  # Corresponding to Close price_1 to Close price_5

# Create a plot for Actual vs Predicted Close Prices for each strike
for strike in strikes_test:
    plt.figure(figsize=(12, 6))

    # Plot actual close prices
    plt.plot(range(len(Test_Put_options)), Test_Put_options[f'Close_{strike}'],
             label=f'Actual Close Price_{strike}(Strike_{strike})', color='blue', marker='o', linestyle='-')

    # Plot predicted close prices
    plt.plot(range(len(Test_Put_options)), Test_Put_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price_{strike} (Strike_{strike})', color='red', marker='x', linestyle='--')

    # Add labels and title
    plt.xlabel('Day')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs Predicted Close Prices for GLD ETF Put Options Close_{strike} ANN+Random_Search (without volatility Input) ANN 8 layers Testing dataset', fontsize=10)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot
    plt.savefig(f'./testing_results/Actual_vs_Predicted_Close_Prices_Close_{strike}_ANN_with_random_Search_8_layers_150_neurons.png')
    plt.show()

# Create histograms of prediction differences for each strike
for strike in strikes_test:
    plt.figure(figsize=(12, 6))
    plt.hist(Test_Put_options[f'Price Prediction Difference_{strike}'], bins=30, color='green', alpha=0.7)
    plt.xlabel(f'Price Prediction Difference in USD$ (Strike_{strike}) Close price_{strike}')
    plt.ylabel('Frequency')
    plt.title(f'Histogram of Prediction Differences for GLD ETF Put Options Close_{strike} (without volatility Input) ANN+Random-search 8 layers Testing dataset', fontsize=10)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the histogram
    plt.savefig(f'./testing_results/Prediction_Differences_Histogram_Put_Options_ANN_with_random_Search_{strike}.png')
    plt.show()

# Create scatter plots for residuals for each strike level
for strike in strikes_test:
    plt.figure(figsize=(14, 6))
    plt.scatter(Test_Put_options.index, Test_Put_options[f'Price Prediction Difference_{strike}'], color='purple', alpha=0.5)
    plt.axhline(0, color='red', linestyle='--', linewidth=1)
    plt.xlabel('Day')
    plt.ylabel(f'Price Prediction Difference in USD$ Close Price_{strike} in USD$')
    plt.title(f'Residuals for GLD ETF Put Option Close Prices ANN with random Search Close_{strike} (without volatility Input) ANN 8 layers Testing dataset', fontsize=10)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the residuals plot
    plt.savefig(f'./testing_results/Residuals_Put_Options_Strike{strike}_Testing_ANN_with_random_Search_{strike}.png')
    plt.show()

# Create a scatter plot for actual vs. predicted close prices for each strike
plt.figure(figsize=(10, 6))
for strike in strikes_test:
    plt.scatter(Test_Put_options[f'Close_{strike}'], Test_Put_options[f'Predicted Price_{strike}'],
                label=f'Strike_{strike} Close_{strike}', alpha=0.5)

# Add a line of perfect prediction for reference
min_price = Test_Put_options[[f'Close_{s}' for s in strikes_test]].min().min()
max_price = Test_Put_options[[f'Close_{s}' for s in strikes_test]].max().max()
plt.plot([min_price, max_price], [min_price, max_price], color='red', linewidth=2, linestyle='--', label='Perfect Prediction Line')

# Label the scatter plot
plt.xlabel('Actual Close Price in USD$')
plt.ylabel('Predicted Close Price in USD$')
plt.title('Actual vs Predicted Close Prices for GLD ETF Put Options\nANN+Random Search (without volatility Input) ANN 8 layers Testing dataset', fontsize=10)
plt.legend()
plt.grid(True)

# Save and show the scatter plot
plt.savefig('./testing_results/Actual_vs_Predicted_Close_Prices_Scatter_ANN_with_random_Search.png')
plt.show()

# Plotting Close prices over time for each strike
for strike in strikes_test:
    plt.figure(figsize=(10, 6))
    plt.plot(test_dates_for_Put, Test_Put_options[f'Close_{strike}'],
             label=f'Actual Close Price Strike_{strike}', marker='o', color='blue')
    plt.plot(test_dates_for_Put, Test_Put_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price Strike_{strike}', linestyle='--', marker='x', color='red')

    plt.xlabel('T - 5 Time years')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs. Predicted Close Prices Over Time for GLD ETF Put Options\nANN+Random-Search Close_{strike} (without volatility Input) ANN 8 layers Testing dataset', fontsize=10)
    plt.xticks(rotation=45)  # Rotate date labels for better readability
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot for each strike
    plt.savefig(f'./testing_results/Actual_vs_Predicted_Close_Prices_Over_Time_Strike_{strike}_ANN_with_random_Search.png')
    plt.show()

# Set up the figure for the overall plots
plt.figure(figsize=(14, 10))

# Plotting Average Price Prediction Difference
plt.subplot(2, 1, 1)
plt.plot(Test_Put_options['T - 5'], Test_Put_options['Overall Average Price Prediction Difference'],
         marker='o', linestyle='-', color='blue')
plt.xlabel('T - 5 Time years')
plt.ylabel('Average Price Prediction Difference in USD$')
plt.title('Overall Average Price Prediction Difference for Put Options\nANN+Random_Search (without volatility Input) ANN 8 layers Testing dataset', fontsize=14)
plt.grid(True)

# Plotting Average Price Prediction Difference in Percentage
plt.subplot(2, 1, 2)
plt.plot(Test_Put_options['T - 5'], Test_Put_options['Overall Average Price Prediction Difference in percentage'],
         marker='o', linestyle='-', color='orange')
plt.xlabel('T - 5 Time in years')
plt.ylabel('Average Price Prediction Difference in Percentage (%)')
plt.title('Overall Average Price Prediction Difference in Percentage for GLD ETF Put Options\nANN+Random_Search (without volatility Input) ANN 8 layers Testing dataset', fontsize=14)
plt.grid(True)

# Adjust layout
plt.tight_layout()

# Save the figure
plt.savefig('./testing_results/Average_Price_Prediction_Differences_ANN_with_random_Search.png')

# Show the plots
plt.show()

# Add overall price prediction difference column
Test_Put_options['Overall Price Prediction Difference'] = Test_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences
plt.figure(figsize=(12, 6))
plt.hist(Test_Put_options['Overall Price Prediction Difference'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference in USD$')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences for GLD ETF Put Options\nANN+Random Search (without volatility Input) ANN 8 layers Testing dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()

# Save and show the overall histogram
plt.savefig('./testing_results/Prediction_Differences_Histogram_Put_Options_Overall_ANN_with_random_Search.png')
plt.show()

# Add overall price prediction difference column for percentage
Test_Put_options['Overall Price Prediction Difference in percentage'] = Res_Put_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences in percentage
plt.figure(figsize=(12, 6))
plt.hist(Res_Put_options['Overall Price Prediction Difference in percentage'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference %')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences in Percentage for GLD ETF Put Options\nANN+Random Search (without volatility Input) ANN 8 layers Testing dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()

# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_Histogram_Put_in_percentage_Options_Overall_ANN_with_random_Search.png')
plt.show()

