


pip install openpyxl parameter


import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import itertools
from tqdm import tqdm
from torch.optim.lr_scheduler import ReduceLROnPlateau
from sklearn.model_selection import ParameterGrid
from sklearn.metrics import mean_squared_error
from torch.utils.data import TensorDataset, DataLoader
import random
from torch.cuda.amp import autocast, GradScaler
from itertools import product


Data_for_call_options = pd.read_excel('train_gld_before_2016.xlsx', sheet_name='GLD_CALL')

batch_size = 2048

exp_dates_for_Call = Data_for_call_options['Exp Date = T']
dates_for_Call = Data_for_call_options['T - 5']
volas_for_Call_percent = Data_for_call_options['21_Day_Percent_Volatility']
volas_for_Call_nominal = Data_for_call_options['21_Day_Volatility']

dates_for_call = Data_for_call_options['T - 5']
Data_for_call_options = Data_for_call_options.drop(columns=['T - 5', 'Exp Date = T'])

Features_for_call_options = Data_for_call_options[['ETF Price on T - 5', 'Strike_1', 'Strike_2', 'Strike_3', 'Strike_4', 'Strike_5','21_Day_Percent_Volatility','21_Day_Volatility']]
Data_Target_call = Data_for_call_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]
Close_prices_call = Data_for_call_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]

Features_for_call_options['ETF Price on T - 5'] = pd.to_numeric(Features_for_call_options['ETF Price on T - 5'], errors='coerce')
Features_for_call_options = Features_for_call_options.dropna(subset=['ETF Price on T - 5'])
Close_prices_call = Close_prices_call.loc[Features_for_call_options.index]

seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

import random
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler
from torch.utils.data import DataLoader, TensorDataset
import numpy as np

class MultiOutputOptionsPricingANN(nn.Module):
    def __init__(self, input_dim, output_dim, neurons_per_layer):
        super(MultiOutputOptionsPricingANN, self).__init__()
        layers = [nn.Linear(input_dim, neurons_per_layer[0]), nn.BatchNorm1d(neurons_per_layer[0]), nn.ReLU()]
        for i in range(1, len(neurons_per_layer)):
            layers += [nn.Linear(neurons_per_layer[i-1], neurons_per_layer[i]), nn.BatchNorm1d(neurons_per_layer[i]), nn.ReLU()]
        layers.append(nn.Linear(neurons_per_layer[-1], output_dim))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

neuron_options = [50, 150, 500, 800, 1000, 1250, 1500, 3500,6000, 7000]
Learning_Rates = [0.00001,0.0001,0.001,0.01,0.1]

num_trials = 50

Features_for_call_tensor = torch.tensor(Features_for_call_options.values, dtype=torch.float32).to(device)
Data_Target_call_tensor = torch.tensor(Data_Target_call.values, dtype=torch.float32).to(device)
call_dataset = TensorDataset(Features_for_call_tensor, Data_Target_call_tensor)
call_loader = DataLoader(call_dataset, batch_size=2048, shuffle=True)

best_val_loss = float('inf')
best_config = None
best_model_state = None
best_epoch_call = None
Best_Learning_rate_call = None



for trial in range(num_trials):
    lr = random.choice(Learning_Rates)

    neurons = [random.choice(neuron_options) for _ in range(8)]

    model = MultiOutputOptionsPricingANN(Features_for_call_tensor.shape[1], 5, neurons).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()
    scaler = torch.amp.GradScaler()

    patience = 50
    max_epochs = 2000
    epochs_no_improve = 0
    best_loss_current = float('inf')

    for epoch in range(max_epochs):
        model.train()
        for features_batch, targets_batch in call_loader:
            optimizer.zero_grad()
            with torch.amp.autocast('cuda:0'):  # Enable mixed precision
                predictions = model(features_batch.to(device))
                loss = criterion(predictions, targets_batch.to(device))
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

        model.eval()
        with torch.no_grad():
            val_predictions = model(Features_for_call_tensor).cpu().numpy()
            val_loss = np.mean((val_predictions - Data_Target_call_tensor.cpu().numpy()) ** 2)

        if val_loss < best_loss_current:
            best_loss_current = val_loss
            epochs_no_improve = 0
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                best_config = (lr, neurons)
                best_epoch_call = epoch + 1
                Best_Learning_rate_call = lr
                best_model_state = model.state_dict()  # Save model state
        else:
            epochs_no_improve += 1

        if epochs_no_improve >= patience:
            print(f"Early stopping at epoch {epoch+1} for trial {trial+1} with neurons {neurons}, val loss {val_loss:.6f}")
            break

    print(f"Trial {trial+1}/{num_trials}: LR={lr}, Neurons={neurons}, Best Loss {best_loss_current:.6f}")
    torch.cuda.reset_peak_memory_stats()  

if best_model_state:
    best_model = MultiOutputOptionsPricingANN(Features_for_call_tensor.shape[1], 5, best_config[1]).to(device)
    best_model.load_state_dict(best_model_state)
    torch.save(best_model_state, './training_results/best_random_search_model.pth')
    print(f"Best model saved with config {best_config}, Best Validation Loss={best_val_loss:.6f}")

    best_model.eval()
    with torch.no_grad():
        train_predictions_Call = best_model(Features_for_call_tensor).cpu().numpy()

    print(f"Final training predictions: {train_predictions_Call[:5]}")  


    def calculate_overall_metrics(true_values, predicted_values):
        mse = mean_squared_error(true_values, predicted_values)
        mae = np.mean(np.abs(true_values - predicted_values))
        mape = np.mean(np.abs((true_values - predicted_values) / true_values)) * 100
        return mse, mae, mape

    overall_mse, overall_mae, overall_mape = calculate_overall_metrics(Close_prices_call.values, train_predictions_Call)

    prediction_differences = {
        f'Strike_{i} Diff': Data_for_call_options[f'Close_{i}'].values - train_predictions_Call[:, i-1]
        for i in range(1, 6)
    }

    avg_prediction_diff = np.mean(np.abs(Data_for_call_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']].values - train_predictions_Call), axis=1)
    avg_price_diff = np.mean(avg_prediction_diff)

assert len(Features_for_call_options['Strike_1']) == len(Data_for_call_options['Close_1']) == len(train_predictions_Call), \
    "Mismatch in array lengths for strike, close, and prediction data."

assert len(avg_prediction_diff) == len(Features_for_call_options), "Mismatch in array length between prediction diff and other features."

num_rows = len(Features_for_call_options)

Res_Call_options = pd.DataFrame({
    'Exp Date = T': exp_dates_for_Call,
    'T - 5': dates_for_Call,
    '21_Day_Percent_Volatility': volas_for_Call_percent,
    '21_Day_Volatility': volas_for_Call_nominal,
    'Strike_1': Features_for_call_options['Strike_1'].values,
    'Close_1': Data_for_call_options['Close_1'].values,
    'Predicted Price_1': train_predictions_Call[:, 0],
    'MSE_1': [overall_mse] * num_rows,
    'MAE_1': [overall_mae] * num_rows,
    'MAPE_1': [overall_mape] * num_rows,
    'Strike_2': Features_for_call_options['Strike_2'].values,
    'Close_2': Data_for_call_options['Close_2'].values,
    'Predicted Price_2': train_predictions_Call[:, 1],
    'MSE_2': [overall_mse] * num_rows,
    'MAE_2': [overall_mae] * num_rows,
    'MAPE_2': [overall_mape] * num_rows,
    'Strike_3': Features_for_call_options['Strike_3'].values,
    'Close_3': Data_for_call_options['Close_3'].values,
    'Predicted Price_3': train_predictions_Call[:, 2],
    'MSE_3': [overall_mse] * num_rows,
    'MAE_3': [overall_mae] * num_rows,
    'MAPE_3': [overall_mape] * num_rows,
    'Strike_4': Features_for_call_options['Strike_4'].values,
    'Close_4': Data_for_call_options['Close_4'].values,
    'Predicted Price_4': train_predictions_Call[:, 3],
    'MSE_4': [overall_mse] * num_rows,
    'MAE_4': [overall_mae] * num_rows,
    'MAPE_4': [overall_mape] * num_rows,
    'Strike_5': Features_for_call_options['Strike_5'].values,
    'Close_5': Data_for_call_options['Close_5'].values,
    'Predicted Price_5': train_predictions_Call[:, 4],
    'MSE_5': [overall_mse] * num_rows,
    'MAE_5': [overall_mae] * num_rows,
    'MAPE_5': [overall_mape] * num_rows,
    'Seed': [seed] * num_rows,
    'Best Epoch': [best_epoch_call] * num_rows,
    'Learning Rate': [Best_Learning_rate_call] * num_rows,
    'Num Neurons': [neurons] * num_rows,
    'Epochs': [best_epoch_call] * num_rows,
    'Overall MSE': [overall_mse] * num_rows,
    'Overall MAE': [overall_mae] * num_rows,
    'Overall MAPE': [overall_mape] * num_rows,
    **{k: v[:num_rows] for k, v in prediction_differences.items()},  
    'Average Price Prediction Diff': [avg_price_diff] * num_rows  
})


for i in range(1, 6):
    Res_Call_options[f'Price Prediction Difference_{i}'] = Res_Call_options[f'Predicted Price_{i}'] - Res_Call_options[f'Close_{i}']

    Res_Call_options[f'Price Prediction Difference in percentage_{i}'] = (
        Res_Call_options[f'Price Prediction Difference_{i}'] / Res_Call_options[f'Close_{i}'] * 100
    )

Res_Call_options['Average Price Prediction Difference'] = Res_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

Res_Call_options['Average Price Prediction Difference in percentage'] = Res_Call_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

Res_Call_options['Overall Average Price Prediction Difference'] = Res_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

Res_Call_options['Overall Average Price Prediction Difference in percentage'] = Res_Call_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)


MSE_Call = ((Res_Call_options[[f'Close_{i}' for i in range(1, 6)]].values -
              Res_Call_options[[f'Predicted Price_{i}' for i in range(1, 6)]].values) ** 2).mean().mean()
MAE_Call = (abs(Res_Call_options[[f'Close_{i}' for i in range(1, 6)]].values -
             Res_Call_options[[f'Predicted Price_{i}' for i in range(1, 6)]].values)).mean().mean()
MAPE_Call = (100 * abs((Res_Call_options[[f'Close_{i}' for i in range(1, 6)]].values -
               Res_Call_options[[f'Predicted Price_{i}' for i in range(1, 6)]].values) /
               Res_Call_options[[f'Close_{i}' for i in range(1, 6)]].values)).mean().mean()

Res_Call_options['MSE'] = [MSE_Call] * len(Res_Call_options)  
Res_Call_options['MAE'] = [MAE_Call] * len(Res_Call_options)  
Res_Call_options['MAPE'] = [MAPE_Call] * len(Res_Call_options)  


print(Res_Call_options.head())
print(f'MSE: {MSE_Call}, MAE: {MAE_Call}, MAPE: {MAPE_Call}')

MSE_Call, MAE_Call, MAPE_Call = calculate_overall_metrics(Close_prices_call.values, train_predictions_Call)

Res_Call_options['Learning rate'] = lr
Res_Call_options['Epoch size'] = best_epoch_call
Res_Call_options['Random seed'] = seed






print(Res_Call_options.head())



Res_Call_options.to_csv('./training_results/Res_Call_options_random_search_without_volatility_input_150-3500.csv', index=False)

print("Results saved to './training_results/Res_Call_options.csv'.")



import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt

testing_Data_for_Call_options = pd.read_excel('test_gld_after_2016.xlsx', sheet_name='GLD_CALL')
test_volas_for_Call_percent = testing_Data_for_Call_options['21_Day_Percent_Volatility']
test_volas_for_Call_nominal = testing_Data_for_Call_options['21_Day_Volatility']

testing_Data_for_Call_options.columns = testing_Data_for_Call_options.columns.str.strip()

testing_Features_for_Call_options = testing_Data_for_Call_options[['ETF Price on T - 5', 'Strike_1', 'Strike_2', 'Strike_3', 'Strike_4', 'Strike_5','21_Day_Percent_Volatility','21_Day_Volatility']].copy()
testing_Data_Target_Call = testing_Data_for_Call_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]

testing_Features_for_Call_options['ETF Price on T - 5'] = pd.to_numeric(testing_Features_for_Call_options['ETF Price on T - 5'], errors='coerce')

testing_Features_for_Call_options = testing_Features_for_Call_options.dropna(subset=['ETF Price on T - 5'])

test_Close_prices_Call = testing_Data_Target_Call.loc[testing_Features_for_Call_options.index]

test_dates_for_Call = testing_Data_for_Call_options['T - 5']
exp_dates_for_Call_test = testing_Data_for_Call_options['Exp Date = T']

testing_Data_for_Call_options = testing_Data_for_Call_options.drop(columns=['Exp Date = T'])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

Call_features_tensor_test = torch.tensor(testing_Features_for_Call_options.values, dtype=torch.float32).to(device)
Call_target_tensor_test = torch.tensor(testing_Data_Target_Call.values, dtype=torch.float32).to(device)

input_features = 8 
output_strikes = 5  

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")



if best_model_state:
    _, best_neurons = best_config

    best_model = MultiOutputOptionsPricingANN(Features_for_call_tensor.shape[1], 5, best_neurons).to(device)
    best_model.load_state_dict(best_model_state)  # Load the saved state dict

    torch.save(best_model_state, './training_results/best_random_search_model.pth')
    print(f"Best model saved with config {best_config}, Best Validation Loss={best_val_loss:.6f}")

    best_model.eval()
    with torch.no_grad():
        train_predictions_Call = best_model(Features_for_call_tensor).cpu().numpy()

    print(f"Final training predictions: {train_predictions_Call[:5]}")



with torch.no_grad(): 
    test_predictions_Call = best_model(Call_features_tensor_test)

test_predictions_Call = test_predictions_Call.cpu().numpy()

assert Call_target_tensor_test.shape == test_predictions_Call.shape, "Shape mismatch between actual and predicted prices."

def Metrics(actual, predicted):
    MSE_test_Call = np.mean((actual - predicted) ** 2, axis=0)  # MSE for each strike
    MAE_test_Call = np.mean(np.abs(actual - predicted), axis=0)  # MAE for each strike
    MAPE_test_Call = np.mean(np.abs((actual - predicted) / (actual + 1e-8)), axis=0) * 100  # MAPE for each strike, avoid division by zero

    return MSE_test_Call, MAE_test_Call, MAPE_test_Call

MSE_test_Call, MAE_test_Call, MAPE_test_Call = Metrics(test_Close_prices_Call.values, test_predictions_Call)

for i in range(len(MSE_test_Call)):
    print(f'Call Options Price_{i+1} - Strike_{i+1}: MSE (testing): {MSE_test_Call[i]:.4f}, MAE (testing): {MAE_test_Call[i]:.4f}, MAPE (testing): {MAPE_test_Call[i]:.2f}%')

Test_Call_options = pd.DataFrame({
    'Exp Date = T': exp_dates_for_Call_test,
    'T - 5': test_dates_for_Call,
    '21_Day_Percent_Volatility': test_volas_for_Call_percent,
    '21_Day_Volatility': test_volas_for_Call_nominal,
    'ETF Price on T - 5': testing_Features_for_Call_options['ETF Price on T - 5'].values,
})

for i in range(1, 6):  # Assuming there are 5 strike prices
    Test_Call_options[f'Strike_{i}'] = testing_Features_for_Call_options[f'Strike_{i}'].values
    Test_Call_options[f'Close_{i}'] = testing_Data_Target_Call[f'Close_{i}'].values  # Actual close prices
    Test_Call_options[f'Predicted Price_{i}'] = test_predictions_Call[:, i - 1]  # Predicted prices

for i in range(1, 6):
    Test_Call_options[f'Price Prediction Difference_{i}'] = Test_Call_options[f'Predicted Price_{i}'] - Test_Call_options[f'Close_{i}']

    Test_Call_options[f'Price Prediction Difference in percentage_{i}'] = (
        Test_Call_options[f'Price Prediction Difference_{i}'] / Test_Call_options[f'Close_{i}'].replace(0, np.nan) * 100
    )

Test_Call_options['Average Price Prediction Difference'] = Test_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

Test_Call_options['Average Price Prediction Difference in percentage'] = Test_Call_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference across all strikes
Test_Call_options['Overall Average Price Prediction Difference'] = Test_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference in percentage across all strikes
Test_Call_options['Overall Average Price Prediction Difference in percentage'] = Test_Call_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create a DataFrame with metrics for each strike price
metrics_df = pd.DataFrame({
    'Strike': [f'Strike_{i+1} Close_{i+1}' for i in range(len(MSE_test_Call))],
    'MSE_test_Call_close': MSE_test_Call,
    'MAE_test_Call_close': MAE_test_Call,
    'MAPE_test_Call_Close': MAPE_test_Call,
})

# Assign overall model performance metrics to all rows
Test_Call_options['MSE'] = np.mean(MSE_test_Call)  # Overall MSE based on close prices
Test_Call_options['MAE'] = np.mean(MAE_test_Call)  # Overall MAE based on close prices
Test_Call_options ['MAPE'] = np.mean(MAPE_test_Call)
Test_Call_options['Learning rate'] = lr  # Assuming you define this in your hyperparameter optimization
Test_Call_options['Epoch size'] = best_epoch_call  # Likewiseest_Call_options['MAPE'] = np.mean(MAPE_test_Call)  # Overall MAPE based on close prices


# Print the DataFrame and metrics for verification
print(Test_Call_options.head())
print(f'MSE: {np.mean(MSE_test_Call):.4f}, MAE: {np.mean(MAE_test_Call):.4f}, MAPE: {np.mean(MAPE_test_Call):.2f}%')

# Combine the metrics with the main DataFrame
Test_Call_options = pd.concat([Test_Call_options, metrics_df], axis=1)

# Save results to Excel
with pd.ExcelWriter('./testing_results/GLD_testing_results_with_ANN_Adam_random_search_Testing_without_volatility_input_Calls_.xlsx') as writer:
    Test_Call_options.to_excel(writer, sheet_name='Call_Options', index=False)

# Display the final DataFrame for verification
print(Test_Call_options.head())






# Define the strike prices to plot
strikes = [1, 2, 3, 4, 5]  # Corresponding to Close price_1 to Close price_5

# Create a plot for Actual vs Predicted Close Prices for each strike
for strike in strikes:
    plt.figure(figsize=(12, 6))

    # Plot actual close prices
    plt.plot(range(len(Res_Call_options)), Res_Call_options[f'Close_{strike}'],
             label=f'Actual Close Price Close_{strike} (Strike_{strike})', color='blue', marker='o', linestyle='-')

    # Plot predicted close prices
    plt.plot(range(len(Res_Call_options)), Res_Call_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price Close_{strike} (Strike_{strike})', color='red', marker='x', linestyle='--')

    # Add labels and title
    plt.xlabel('Day')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs Predicted Call options Close Prices using ANN+Random-Search for Close_{strike} (without volatility input) ANN 8 layers Training dataset', fontsize=10)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot
    plt.savefig(f'./training_results/Actual_vs_Predicted_ANN_randomSearch_Strike_{strike}_Close_{strike}_Volatility_Input.png')
    plt.show()


# Create scatter plots for residuals for each strike level
for strike in strikes:
    plt.figure(figsize=(14, 6))
    plt.scatter(Res_Call_options.index, Res_Call_options[f'Price Prediction Difference_{strike}'], color='purple', alpha=0.5)
    plt.axhline(0, color='red', linestyle='--', linewidth=1)
    plt.xlabel('Day')
    plt.ylabel(f'Price Prediction Difference (Strike_{strike}) in USD$')
    plt.title(f'Residuals for Call option Close Price_{strike} Close Prices (ANN+Random-Search) (without volatility input) ANN 8 layers Training dataset', fontsize=12)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the residuals plot
    plt.savefig(f'./training_results/Residuals_Call_Options_ANN_randomSearch_Strike_{strike}_Volatility_Input.png')
    plt.show()

# Create a scatter plot for actual vs. predicted close prices for each strike
plt.figure(figsize=(10, 6))
for strike in strikes:
    plt.scatter(Res_Call_options[f'Close_{strike}'], Res_Call_options[f'Predicted Price_{strike}'],
                label=f'Strike_{strike} Close_{strike}', alpha=0.5)

# Add a line of perfect prediction for reference
min_price = Res_Call_options[[f'Close_{s}' for s in strikes]].min().min()
max_price = Res_Call_options[[f'Close_{s}' for s in strikes]].max().max()
plt.plot([min_price, max_price], [min_price, max_price], color='red', linewidth=2, linestyle='--', label='Perfect Prediction Line')

# Label the scatter plot
plt.xlabel('Actual Close Price in USD$')
plt.ylabel('Predicted Close Price in USD$')
plt.title('Actual vs Predicted Call option Close Prices using ANN+Random-Search (without volatility input) ANN 8 layers Training dataset', fontsize=10)
plt.legend()
plt.grid(True)

# Save and show the scatter plot
plt.savefig('./training_results/Actual_vs_Predicted_ANN_randomSearch_Scatter_Volatility_Input.png')
plt.show()

# Plot actual and predicted close prices over time for each strike
plt.figure(figsize=(12, 6))

for strike in strikes:
    plt.figure(figsize=(10, 6))  # Create a new figure for each strike
    plt.plot(dates_for_Call, Res_Call_options[f'Close_{strike}'],
             label=f'Actual Close Price Strike_{strike}', marker='o', color='blue')
    plt.plot(dates_for_Call, Res_Call_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price Strike_{strike}', linestyle='--', marker='x', color='red')

    plt.xlabel('T - 5 Time years')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs. Predicted Call option Close prices using ANN+Random_Search for Close_{strike} Over Time (without volatility input) ANN 8 layers Training dataset', fontsize=10)
    plt.xticks(rotation=45)  # Rotate date labels for better readability
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot for each strike
    plt.savefig(f'./training_results/Actual_vs_Predicted_ANN_randomSearch_Strike_{strike}_Over_Time_Volatility_Input.png')
    plt.show()

# Set up the figure for the plots
plt.figure(figsize=(14, 10))

# Plotting Average Price Prediction Difference
plt.subplot(2, 1, 1)
plt.plot(Res_Call_options['T - 5'], Res_Call_options['Overall Average Price Prediction Difference'],
         marker='o', linestyle='-', color='blue')
plt.xlabel('T - 5 Time years')
plt.ylabel('Average Price Prediction Difference in USD$')
plt.title('Overall Average Price Prediction Difference using ANN+Random-Search for Call Options (without volatility input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)

# Plotting Average Price Prediction Difference in Percentage
plt.subplot(2, 1, 2)
plt.plot(Res_Call_options['T - 5'], Res_Call_options['Overall Average Price Prediction Difference in percentage'],
         marker='o', linestyle='-', color='orange')
plt.xlabel('T - 5 Time years')
plt.ylabel('Average Price Prediction Difference in Percentage (%)')
plt.title('Average Price Prediction Difference in Percentage using ANN+Random-Search for Call Options (without volatility input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)

# Adjust layout
plt.tight_layout()

# Save the figure
plt.savefig('./training_results/Overall_Price_Prediction_Differences_ANN_randomSearch_Volatility_Input.png')

# Show the plots
plt.show()

# Create histograms of prediction differences for each strike
for strike in strikes:
    plt.figure(figsize=(12, 6))
    plt.hist(Res_Call_options[f'Price Prediction Difference_{strike}'], bins=30, color='green', alpha=0.7)
    plt.xlabel(f'Close_{strike} Price Prediction Difference in USD$ (Close Price_{strike}) ')
    plt.ylabel('Frequency')
    plt.title(f'Histogram of Close Price Prediction Differences for Close Price_{strike} using ANN + random Search without volatility input', fontsize=10)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the histogram
    plt.savefig(f'./training_results/Prediction_Differences_Histogram_Strike_{strike}_ANN_randomSearch_Volatility_Input.png')
    plt.show()



# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_Histogram_Overall_ANN_randomSearch_Volatility_Input.png')
plt.show()


# Add overall price prediction difference column
Res_Call_options['Overall Price Prediction Difference'] = Res_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences
plt.figure(figsize=(12, 6))
plt.hist(Res_Call_options['Overall Price Prediction Difference'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference in USD$')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences for GLD ETF Call Options\nANN+Random Search (without volatility input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()

# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_Histogram_Call_Options_Overall_ANN_with_random_Search.png')
plt.show()

# Add overall price prediction difference column for percentage
Res_Call_options['Overall Price Prediction Difference in percentage'] = Res_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences in percentage
plt.figure(figsize=(12, 6))
plt.hist(Res_Call_options['Overall Price Prediction Difference in percentage'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference %')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences in Percentage for GLD ETF Call Options\nANN+Random Search (without volatility input) ANN 8 layers Training dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()



# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_in_Percentage_Histogram_Overall_ANN_randomSearch_Volatility_Input.png')
plt.show()






import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt

# Load testing data
testing_Data_for_Call_options = pd.read_excel('test_gld_after_2016.xlsx', sheet_name='GLD_CALL')
test_volas_for_Call_percent = testing_Data_for_Call_options['21_Day_Percent_Volatility']
test_volas_for_Call_nominal = testing_Data_for_Call_options['21_Day_Volatility']

# Clean column names
testing_Data_for_Call_options.columns = testing_Data_for_Call_options.columns.str.strip()

# Prepare features and targets for Call options
testing_Features_for_Call_options = testing_Data_for_Call_options[['ETF Price on T - 5', 'Strike_1', 'Strike_2', 'Strike_3', 'Strike_4', 'Strike_5']].copy()
testing_Data_Target_Call = testing_Data_for_Call_options[['Close_1', 'Close_2', 'Close_3', 'Close_4', 'Close_5']]

# Convert columns to numeric
testing_Features_for_Call_options['ETF Price on T - 5'] = pd.to_numeric(testing_Features_for_Call_options['ETF Price on T - 5'], errors='coerce')

# Drop rows with missing values in the feature set
testing_Features_for_Call_options = testing_Features_for_Call_options.dropna(subset=['ETF Price on T - 5'])

# Ensure the target aligns with the filtered features
test_Close_prices_Call = testing_Data_Target_Call.loc[testing_Features_for_Call_options.index]

# Get test dates and volatility
test_dates_for_Call = testing_Data_for_Call_options['T - 5']
exp_dates_for_Call_test = testing_Data_for_Call_options['Exp Date = T']

# Drop 'Exp Date = T' column for scaling and prediction
testing_Data_for_Call_options = testing_Data_for_Call_options.drop(columns=['Exp Date = T'])

# Check if CUDA is available and set the device (reuse if defined previously)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Tensor conversion for testing features and targets, with CUDA support
Call_features_tensor_test = torch.tensor(testing_Features_for_Call_options.values, dtype=torch.float32).to(device)
Call_target_tensor_test = torch.tensor(testing_Data_Target_Call.values, dtype=torch.float32).to(device)

# Define input features and output strikes based on your dataset
input_features = 8  # Number of features in your testing data (e.g., ETF Price, Strike prices, Volatility, etc.)
output_strikes = 5  # Number of strike prices you're predicting (Close_1, Close_2, ..., Close_5)

# Check if CUDA is available and set the device (reuse if defined previously)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")



# Assuming `best_config` is a tuple containing (learning_rate, neuron configuration)
if best_model_state:
    # Retrieve the best neuron configuration
    _, best_neurons = best_config

    # Initialize a model with the exact configuration from the best random search trial
    best_model = MultiOutputOptionsPricingANN(Features_for_call_tensor.shape[1], 5, best_neurons).to(device)
    best_model.load_state_dict(best_model_state)  # Load the saved state dict

    # Save the best model's state dict
    torch.save(best_model_state, './training_results/best_random_search_model.pth')
    print(f"Best model saved with config {best_config}, Best Validation Loss={best_val_loss:.6f}")

    # Generate predictions using the best model
    best_model.eval()
    with torch.no_grad():
        train_predictions_Call = best_model(Features_for_call_tensor).cpu().numpy()

    # Print first 5 predictions for inspection
    print(f"Final training predictions: {train_predictions_Call[:5]}")



# Make predictions with the loaded Call options model
with torch.no_grad():  # Disable gradient calculation
    test_predictions_Call = best_model(Call_features_tensor_test)

# Move predictions back to CPU and convert to numpy for further processing if needed
test_predictions_Call = test_predictions_Call.cpu().numpy()

# Ensure both actual and predicted arrays have the same shape
assert Call_target_tensor_test.shape == test_predictions_Call.shape, "Shape mismatch between actual and predicted prices."

# Function to calculate metrics
def Metrics(actual, predicted):
    MSE_test_Call = np.mean((actual - predicted) ** 2, axis=0)  # MSE for each strike
    MAE_test_Call = np.mean(np.abs(actual - predicted), axis=0)  # MAE for each strike
    MAPE_test_Call = np.mean(np.abs((actual - predicted) / (actual + 1e-8)), axis=0) * 100  # MAPE for each strike, avoid division by zero

    return MSE_test_Call, MAE_test_Call, MAPE_test_Call

# Calculate metrics for each Call option
MSE_test_Call, MAE_test_Call, MAPE_test_Call = Metrics(test_Close_prices_Call.values, test_predictions_Call)

# Print each metric for each close price in Calls
for i in range(len(MSE_test_Call)):
    print(f'Call Options Price_{i+1} - Strike_{i+1}: MSE (testing): {MSE_test_Call[i]:.4f}, MAE (testing): {MAE_test_Call[i]:.4f}, MAPE (testing): {MAPE_test_Call[i]:.2f}%')

# Create the Test_Call_options DataFrame
Test_Call_options = pd.DataFrame({
    'Exp Date = T': exp_dates_for_Call_test,
    'T - 5': test_dates_for_Call,
    '21_Day_Percent_Volatility': test_volas_for_Call_percent,
    '21_Day_Volatility': test_volas_for_Call_nominal,
    'ETF Price on T - 5': testing_Features_for_Call_options['ETF Price on T - 5'].values,
})

# Add strike prices and predictions to the DataFrame
for i in range(1, 6):  # Assuming there are 5 strike prices
    Test_Call_options[f'Strike_{i}'] = testing_Features_for_Call_options[f'Strike_{i}'].values
    Test_Call_options[f'Close_{i}'] = testing_Data_Target_Call[f'Close_{i}'].values  # Actual close prices
    Test_Call_options[f'Predicted Price_{i}'] = test_predictions_Call[:, i - 1]  # Predicted prices

# Calculate the prediction differences and percentage differences for each strike
for i in range(1, 6):
    # Calculate the difference between predicted and actual close prices
    Test_Call_options[f'Price Prediction Difference_{i}'] = Test_Call_options[f'Predicted Price_{i}'] - Test_Call_options[f'Close_{i}']

    # Calculate the percentage difference
    Test_Call_options[f'Price Prediction Difference in percentage_{i}'] = (
        Test_Call_options[f'Price Prediction Difference_{i}'] / Test_Call_options[f'Close_{i}'].replace(0, np.nan) * 100
    )

# Calculate average price prediction differences
Test_Call_options['Average Price Prediction Difference'] = Test_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

Test_Call_options['Average Price Prediction Difference in percentage'] = Test_Call_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference across all strikes
Test_Call_options['Overall Average Price Prediction Difference'] = Test_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Overall Average Price Prediction Difference in percentage across all strikes
Test_Call_options['Overall Average Price Prediction Difference in percentage'] = Test_Call_options[
    [f'Price Prediction Difference in percentage_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create a DataFrame with metrics for each strike price
metrics_df = pd.DataFrame({
    'Strike': [f'Strike_{i+1} Close_{i+1}' for i in range(len(MSE_test_Call))],
    'MSE_test_Call_close': MSE_test_Call,
    'MAE_test_Call_close': MAE_test_Call,
    'MAPE_test_Call_Close': MAPE_test_Call,
})

# Assign overall model performance metrics to all rows
Test_Call_options['MSE'] = np.mean(MSE_test_Call)  # Overall MSE based on close prices
Test_Call_options['MAE'] = np.mean(MAE_test_Call)  # Overall MAE based on close prices
Test_Call_options ['MAPE'] = np.mean(MAPE_test_Call)
Test_Call_options['Learning rate'] = lr  # Assuming you define this in your hyperparameter optimization
Test_Call_options['Epoch size'] = best_epoch_call  # Likewiseest_Call_options['MAPE'] = np.mean(MAPE_test_Call)  # Overall MAPE based on close prices


# Print the DataFrame and metrics for verification
print(Test_Call_options.head())
print(f'MSE: {np.mean(MSE_test_Call):.4f}, MAE: {np.mean(MAE_test_Call):.4f}, MAPE: {np.mean(MAPE_test_Call):.2f}%')

# Combine the metrics with the main DataFrame
Test_Call_options = pd.concat([Test_Call_options, metrics_df], axis=1)

# Save results to Excel
with pd.ExcelWriter('./testing_results/GLD_testing_results_with_ANN_Adam_random_search_Testing_without_volatility_input_Calls_.xlsx') as writer:
    Test_Call_options.to_excel(writer, sheet_name='Call_Options', index=False)

# Display the final DataFrame for verification
print(Test_Call_options.head())






# Define the strike prices to plot
strikes_test = [1, 2, 3, 4, 5]  # Corresponding to Close price_1 to Close price_5

# Create a plot for Actual vs Predicted Close Prices for each strike
for strike in strikes_test:
    plt.figure(figsize=(12, 6))

    # Plot actual close prices
    plt.plot(range(len(Test_Call_options)), Test_Call_options[f'Close_{strike}'],
             label=f'Actual Close Price_{strike}(Strike_{strike})', color='blue', marker='o', linestyle='-')

    # Plot predicted close prices
    plt.plot(range(len(Test_Call_options)), Test_Call_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price_{strike} (Strike_{strike})', color='red', marker='x', linestyle='--')

    # Add labels and title
    plt.xlabel('Day')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs Predicted Call Close Prices for GLD ETF Call Options Close_{strike} ANN+Random_Search (without volatility input) ANN 8 layers Testing dataset', fontsize=10)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot
    plt.savefig(f'./testing_results/Actual_vs_Predicted_Close_Prices_Close_{strike}_ANN_with_random_Search_8_layers_150_neurons.png')
    plt.show()

# Create histograms of prediction differences for each strike
for strike in strikes_test:
    plt.figure(figsize=(12, 6))
    plt.hist(Test_Call_options[f'Price Prediction Difference_{strike}'], bins=30, color='green', alpha=0.7)
    plt.xlabel(f'Price Prediction Difference in USD$ (Strike_{strike}) Close price_{strike}')
    plt.ylabel('Frequency')
    plt.title(f'Histogram of Prediction Differences for GLD ETF Call Options Close_{strike} (without volatility input) ANN+Random-search 8 layers Testing dataset', fontsize=10)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the histogram
    plt.savefig(f'./testing_results/Prediction_Differences_Histogram_Call_Options_ANN_with_random_Search_{strike}.png')
    plt.show()

# Create scatter plots for residuals for each strike level
for strike in strikes_test:
    plt.figure(figsize=(14, 6))
    plt.scatter(Test_Call_options.index, Test_Call_options[f'Price Prediction Difference_{strike}'], color='purple', alpha=0.5)
    plt.axhline(0, color='red', linestyle='--', linewidth=1)
    plt.xlabel('Day')
    plt.ylabel(f'Price Prediction Difference in USD$ Close Price_{strike} in USD$')
    plt.title(f'Residuals for GLD ETF Call Option Close Prices ANN with random Search Close_{strike} (without volatility input) ANN 8 layers Testing dataset', fontsize=10)
    plt.grid(True)
    plt.tight_layout()

    # Save and show the residuals plot
    plt.savefig(f'./testing_results/Residuals_Call_Options_Strike{strike}_Testing_ANN_with_random_Search_{strike}.png')
    plt.show()

# Create a scatter plot for actual vs. predicted close prices for each strike
plt.figure(figsize=(10, 6))
for strike in strikes_test:
    plt.scatter(Test_Call_options[f'Close_{strike}'], Test_Call_options[f'Predicted Price_{strike}'],
                label=f'Strike_{strike} Close_{strike}', alpha=0.5)

# Add a line of perfect prediction for reference
min_price = Test_Call_options[[f'Close_{s}' for s in strikes_test]].min().min()
max_price = Test_Call_options[[f'Close_{s}' for s in strikes_test]].max().max()
plt.plot([min_price, max_price], [min_price, max_price], color='red', linewidth=2, linestyle='--', label='Perfect Prediction Line')

# Label the scatter plot
plt.xlabel('Actual Close Price in USD$')
plt.ylabel('Predicted Close Price in USD$')
plt.title('Actual vs Predicted Call Close Prices for GLD ETF Call Options\nANN+Random Search (without volatility input) ANN 8 layers Testing dataset', fontsize=10)
plt.legend()
plt.grid(True)

# Save and show the scatter plot
plt.savefig('./testing_results/Actual_vs_Predicted_Close_Prices_Scatter_ANN_with_random_Search.png')
plt.show()

# Plotting Close prices over time for each strike
for strike in strikes_test:
    plt.figure(figsize=(10, 6))
    plt.plot(test_dates_for_Call, Test_Call_options[f'Close_{strike}'],
             label=f'Actual Close Price Strike_{strike}', marker='o', color='blue')
    plt.plot(test_dates_for_Call, Test_Call_options[f'Predicted Price_{strike}'],
             label=f'Predicted Close Price Strike_{strike}', linestyle='--', marker='x', color='red')

    plt.xlabel('T - 5 Time years')
    plt.ylabel('Close Price in USD$')
    plt.title(f'Actual vs. Predicted Call Close Prices Over Time for GLD ETF Call Options\nANN+Random-Search Close_{strike} (without volatility input) ANN 8 layers Testing dataset', fontsize=10)
    plt.xticks(rotation=45)  # Rotate date labels for better readability
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    # Save and show the plot for each strike
    plt.savefig(f'./testing_results/Actual_vs_Predicted_Close_Prices_Over_Time_Strike_{strike}_ANN_with_random_Search.png')
    plt.show()

# Set up the figure for the overall plots
plt.figure(figsize=(14, 10))

# Plotting Average Price Prediction Difference
plt.subplot(2, 1, 1)
plt.plot(Test_Call_options['T - 5'], Test_Call_options['Overall Average Price Prediction Difference'],
         marker='o', linestyle='-', color='blue')
plt.xlabel('T - 5 Time years')
plt.ylabel('Average Price Prediction Difference in USD$')
plt.title('Overall Average Price Prediction Difference for Call Options\nANN+Random_Search (without volatility input) ANN 8 layers Testing dataset', fontsize=12)
plt.grid(True)

# Plotting Average Price Prediction Difference in Percentage
plt.subplot(2, 1, 2)
plt.plot(Test_Call_options['T - 5'], Test_Call_options['Overall Average Price Prediction Difference in percentage'],
         marker='o', linestyle='-', color='orange')
plt.xlabel('T - 5 Time in years')
plt.ylabel('Average Price Prediction Difference in Percentage (%)')
plt.title('Overall Average Price Prediction Difference in Percentage for GLD ETF Call Options\nANN+Random_Search (without volatility input) ANN 8 layers Testing dataset', fontsize=12)
plt.grid(True)

# Adjust layout
plt.tight_layout()

# Save the figure
plt.savefig('./testing_results/Average_Price_Prediction_Differences_ANN_with_random_Search.png')

# Show the plots
plt.show()

# Add overall price prediction difference column
Test_Call_options['Overall Price Prediction Difference'] = Test_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences
plt.figure(figsize=(12, 6))
plt.hist(Test_Call_options['Overall Price Prediction Difference'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference in USD$')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences for GLD ETF Call Options\nANN+Random Search (without volatility input) ANN 8 layers Testing dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()

# Save and show the overall histogram
plt.savefig('./testing_results/Prediction_Differences_Histogram_Call_Options_Overall_ANN_with_random_Search.png')
plt.show()

# Add overall price prediction difference column for percentage
Test_Call_options['Overall Price Prediction Difference in percentage'] = Res_Call_options[
    [f'Price Prediction Difference_{i}' for i in range(1, 6)]
].mean(axis=1)

# Create histogram for overall prediction differences in percentage
plt.figure(figsize=(12, 6))
plt.hist(Res_Call_options['Overall Price Prediction Difference in percentage'], bins=30, color='blue', alpha=0.7)
plt.xlabel('Overall Price Prediction Difference %')
plt.ylabel('Frequency')
plt.title('Histogram of Overall Prediction Differences in Percentage for GLD ETF Call Options\nANN+Random Search (without volatility input) ANN 8 layers Testing dataset', fontsize=10)
plt.grid(True)
plt.tight_layout()

# Save and show the overall histogram
plt.savefig('./training_results/Prediction_Differences_Histogram_Call_in_percentage_Options_Overall_ANN_with_random_Search.png')
plt.show()

