

!pip install numpy  seaborn torch pandas scipy scikit-learn mplfinance sympy torch


import numpy as np
import pandas as pd
from scipy.stats import norm
from google.colab import files
import numpy as np
import pandas as pd
from scipy.stats import norm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from scipy.stats import norm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt





import numpy as np
import pandas as pd
from scipy.stats import norm

def BlackScholes_Call_Price(Spot_Price, Strike_Price, Time_Maturity, Risk_FreeRate, Volatility):
    assert Spot_Price.shape == Strike_Price.shape == Time_Maturity.shape == Risk_FreeRate.shape == Volatility.shape, "Input array shapes do not match"
    D1 = (np.log(Spot_Price/ Strike_Price) + (Risk_FreeRate + 0.5 * Volatility ** 2) * Time_Maturity) / (Volatility * np.sqrt(Time_Maturity))
    D2 = D1 - Volatility * np.sqrt(TimeMaturity)
    NormalD1 = norm.cdf(D1)
    NormalD2 = norm.cdf(D2)
    Call_Price = Spot_Price * NormalD1 - Strike_Price * np.exp(-RiskFreeRate * TimeMaturity) * NormalD2
    return Call_Price, NormalD1, NormalD2

size = 1000

def Check_Gen_Data(data):
    SpotPriceRange = (0, 100)
    StrikePriceRange = (20, 80)
    RiskFreeRateRange = (0, 0.2)
    TimeMaturityRange = (0.04, 2)
    VolatilityRange = (0, 0.35)

    CheckTheSpotPrice= all(SpotPriceRange[0] <= data['Spot-Price']) and all(data['Spot-Price'] <= SpotPriceRange[1])
    CheckTheStrikePrice = all(StrikePriceRange[0] <= data['Strike-Price']) and all(data['Strike-Price'] <= StrikePriceRange[1])
    CheckTheRiskFreeRate = all(RiskFreeRateRange[0] <= data['Risk-Free-Rate']) and all(data['Risk-Free-Rate'] <= RiskFreeRateRange[1])
    CheckTheTime_to_maturity = all(TimeMaturityRange[0] <= data['Time-to-Maturity']) and all(data['Time-to-Maturity'] <= TimeMaturityRange[1])
    CheckTheVolatility = all(VolatilityRange[0] <= data['Volatility']) and all(data['Volatility'] <= VolatilityRange[1])
    return CheckTheSpotPrice and CheckTheStrikePrice and CheckTheRiskFreeRate and CheckTheTime_to_maturity and CheckTheVolatility

np.random.seed(42)
Spot_Price = np.random.uniform(low=0, high=100, size = 1000)
Strike_Price = np.random.uniform(low=20, high=100, size = 1000)
TimeMaturity = np.random.uniform(low=0.04, high=2, size = 1000)
RiskFreeRate = np.random.uniform(low=0, high=0.2, size = 1000)
Volatility = np.random.uniform(low=0, high=0.35, size = 1000)

OptionPrices, NormalD1, NormalD2 = BlackScholes_Call_Price(Spot_Price, Strike_Price, TimeMaturity, RiskFreeRate, Volatility)

data = pd.DataFrame({
    'Spot-Price': Spot_Price,
    'Strike-Price': Strike_Price,
    'Risk-Free-Rate': RiskFreeRate,
    'Time-to-Maturity': TimeMaturity,
    'Volatility': Volatility,
    'Call-Option-Price': OptionPrices,


})

Is_the_data_correct =  Check_Gen_Data(data)

if Is_the_data_correct:
    print("The generated data is within the predefined ranges.")


data.to_csv('options_data_fixed.csv', index=False)
files.download('options_data_fixed.csv')





import numpy as np
import pandas as pd
from scipy.stats import norm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
import torch.optim as optim
import random




seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)




def BlackScholes_Call_Price(Spot_Price, Strike_Price, Time_Maturity, Risk_FreeRate, Volatility):
    assert Spot_Price.shape == Strike_Price.shape == Time_Maturity.shape == Risk_FreeRate.shape == Volatility.shape, "Input array shapes do not match"
    D1 = (np.log(Spot_Price/ Strike_Price) + (Risk_FreeRate + 0.5 * Volatility ** 2) * Time_Maturity) / (Volatility * np.sqrt(Time_Maturity))
    D2 = D1 - Volatility * np.sqrt(TimeMaturity)
    NormalD1 = norm.cdf(D1)
    NormalD2 = norm.cdf(D2)
    Call_Price = Spot_Price * NormalD1 - Strike_Price * np.exp(-RiskFreeRate * TimeMaturity) * NormalD2
    return Call_Price, NormalD1, NormalD2

size_3 =  100

def Check_Gen_Data(data):
    SpotPriceRange = (0, 100)
    StrikePriceRange = (20, 80)
    RiskFreeRateRange = (0, 0.2)
    TimeMaturityRange = (0.04, 2)
    VolatilityRange = (0, 0.35)

    CheckTheSpotPrice= all(SpotPriceRange[0] <= data['Spot-Price']) and all(data['Spot-Price'] <= SpotPriceRange[1])
    CheckTheStrikePrice = all(StrikePriceRange[0] <= data['Strike-Price']) and all(data['Strike-Price'] <= StrikePriceRange[1])
    CheckTheRiskFreeRate = all(RiskFreeRateRange[0] <= data['Risk-Free-Rate']) and all(data['Risk-Free-Rate'] <= RiskFreeRateRange[1])
    CheckTheTime_to_maturity = all(TimeMaturityRange[0] <= data['Time-to-Maturity']) and all(data['Time-to-Maturity'] <= TimeMaturityRange[1])
    CheckTheVolatility= all(VolatilityRange[0] <= data['Volatility']) and all(data['Volatility'] <= VolatilityRange[1])
    return CheckTheSpotPrice and CheckTheStrikePrice and CheckTheRiskFreeRate and CheckTheTime_to_maturity and CheckTheVolatility

np.random.seed(42)
Spot_Price = np.random.uniform(low=0, high=100, size= size_3)
Strike_Price = np.random.uniform(low=20, high=80, size = size_3)
TimeMaturity = np.random.uniform(low=0.04, high=2, size = size_3)
RiskFreeRate = np.random.uniform(low=0, high=0.2, size = size_3)
Volatility = np.random.uniform(low=0, high=0.35, size = size_3)

OptionPrices, NormalD1, NormalD2 = BlackScholes_Call_Price(Spot_Price, Strike_Price, TimeMaturity, RiskFreeRate, Volatility)

data = pd.DataFrame({
    'Spot-Price': Spot_Price,
    'Strike-Price': Strike_Price,
    'Risk-Free-Rate': RiskFreeRate,
    'Time-to-Maturity': TimeMaturity,
    'Volatility': Volatility,
    'Call-Option-Price': OptionPrices,


})

Is_the_data_correct =  Check_Gen_Data(data)

if Is_the_data_correct:
    print("The generated data is within the predefined ranges.")
else:
    print("The generated data is not within the predefined ranges.")


features = data[['Spot-Price', 'Strike-Price', 'Risk-Free-Rate', 'Time-to-Maturity', 'Volatility']]
Data_Target = data['Call-Option-Price']

scaler = MinMaxScaler()

ScaledFeatures = scaler.fit_transform(features)

XTrain, TestX, YTrain, TestY = train_test_split (ScaledFeatures, Data_Target, test_size=0.2, random_state=42)

XTrain_tensor = torch.tensor(XTrain, dtype=torch.float32)
YTrain_tensor = torch.tensor(YTrain.values, dtype=torch.float32).view(-1, 1)

TestX_tensor = torch.tensor(TestX, dtype=torch.float32)
TestY_tensor = torch.tensor(TestY.values, dtype=torch.float32).view(-1, 1)

class BlackScholesNN(nn.Module):
    def __init__(self, Input_Param, Number_Of_Neurons, Output_param):
        super(BlackScholesNN, self).__init__()
        self.Layer1 = nn.Linear(Input_Param, Number_Of_Neurons)
        self.relu1 = nn.ReLU()
        self.Layer2 = nn.Linear(Number_Of_Neurons, Output_param)

    def forward(self, x):
        x = self.Layer1(x)
        x = self.relu1(x)
        x = self.Layer2(x)
        return x

Input_Param = XTrain_tensor.shape[1]
Output_param = 1
Number_Of_Neurons = 115

model = BlackScholesNN(Input_Param, Number_Of_Neurons, Output_param)
ErrorCriterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001)
Epoch_Size = 1500

for Ep in range(Epoch_Size):
    outputs = model(XTrain_tensor)
    loss = ErrorCriterion(outputs, YTrain_tensor)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (Ep + 1) % 100 == 0:
        print(f'Epoch [{Ep+1}/{Epoch_Size}], Loss: {loss.item():.4f}')


with torch.no_grad():
    model.eval()
    all_data_tensor = torch.tensor(ScaledFeatures, dtype=torch.float32)
    AllThePredictions = model(all_data_tensor)
    test_predictions = model(TestX_tensor)

MeanSquaredLoss = ErrorCriterion(test_predictions, TestY_tensor).item()

print(f'Mean Squared Error (MSE) on Training Set: {MeanSquaredLoss:.4f}')

AllThePredictionsrelu = torch.relu(AllThePredictions)


if torch.any(AllThePredictionsrelu < 0):
    Random_Coeff = torch.rand_like(AllThePredictionsrelu)
    Tailored_predictions = AllThePredictionsrelu + Random_Coeff * (1 - AllThePredictionsrelu)
else:
    Tailored_predictions = AllThePredictionsrelu


Tailored_predictions_squeezed = Tailored_predictions.numpy().squeeze()


predictions = Tailored_predictions_squeezed.reshape(-1, 1)
AllPredsRelu_Numpy = AllThePredictionsrelu.numpy()

predictions_data = pd.DataFrame({
    'Neural Network Prediction': predictions.flatten()
})

Predictions_Data = pd.concat([data.reset_index(drop=True), pd.DataFrame(AllPredsRelu_Numpy, columns=['Neural Network Prediction'])], axis=1)

Predictions_Data.to_csv('options_fixed.csv', index=False)
Predictions_Data.to_csv('options_fixed.txt', index=False)

Predictions_Data = pd.read_csv('options_fixed.csv')

Predictions_Data['Prediction-Difference'] = Predictions_Data['Neural Network Prediction'] - Predictions_Data['Call-Option-Price']

Average_Diff = Predictions_Data['Prediction-Difference'].mean()
Standard_Deviation = Predictions_Data['Prediction-Difference'].std()

print(f'Average Difference: {Average_Diff:.4f}')
print(f'Standard Deviation: {Standard_Deviation:.4f}')

Predictions_Data['Average Difference'] = Average_Diff
Predictions_Data['Standard Deviation'] = Standard_Deviation
Predictions_Data['Mean Squared Error'] = MeanSquaredLoss

Predictions_Data.to_csv('./option_price_stats_neurons(115)_layers(3)_SGD.csv', index=False)
Predictions_Data.to_csv('./option_price_stats_neurons(115)_layers(3)_SGD.txt', index=False)

plt.figure(figsize=(14, 8))
plt.plot(Predictions_Data.index, Predictions_Data['Call-Option-Price'], label='Actual Option Prices', marker='o')
plt.plot(Predictions_Data.index, Predictions_Data['Neural Network Prediction'], label='Neural Network Predictions', marker='x', color='orange')
plt.title('Project 1. : Actual call option price vs Neural Network Price Predictions - Initial ANN configuration (3 layers 115 neurons) with SGD - 100 data points training dataset', fontsize=11 )
plt.xlabel('Data Points', fontsize=11)
plt.ylabel('Option Prices', fontsize=11)
plt.legend()
plt.savefig('./Line-plot_3layers.pdf')
plt.show()

plt.figure(figsize=(14, 6))
plt.hist(Predictions_Data['Prediction-Difference'], bins=25, color='skyblue', edgecolor='black', density=True)
plt.title('Project 1. : Histogram of options price prediction differences Initial ANN configuration 3 layers 115 neurons with SGD - 100 data points training dataset', fontsize=11)
plt.xlabel('Price prediction difference', fontsize=11)
plt.ylabel('Frequency (Density)', fontsize=11)
plt.savefig('./histogram_SGD_ 3layers.pdf')
plt.show()


import numpy as np
import pandas as pd
from scipy.stats import norm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import random

seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)


if torch.cuda.is_available():
    device = torch.device("cuda")
    print("CUDA is available. Using GPU for computations.")
else:
    device = torch.device("cpu")
    print("CUDA is not available. Using CPU for computations.")


def BlackScholes_Call_Price(Spot_Price, Strike_Price, Time_Maturity, Risk_FreeRate, Volatility):
    assert Spot_Price.shape == Strike_Price.shape == Time_Maturity.shape == Risk_FreeRate.shape == Volatility.shape, "Input array shapes do not match"
    D1 = (np.log(Spot_Price/ Strike_Price) + (Risk_FreeRate + 0.5 * Volatility ** 2) * Time_Maturity) / (Volatility * np.sqrt(Time_Maturity))
    D2 = D1 - Volatility * np.sqrt(TimeMaturity)
    NormalD1 = norm.cdf(D1)
    NormalD2 = norm.cdf(D2)
    Call_Price = Spot_Price * NormalD1 - Strike_Price * np.exp(-RiskFreeRate * TimeMaturity) * NormalD2
    return Call_Price, NormalD1, NormalD2


size_a = 100

def Check_Gen_Data(data):
    SpotPriceRange = (0, 100)
    StrikePriceRange = (20, 80)
    RiskFreeRateRange = (0, 0.2)
    TimeMaturityRange = (0.04, 2)
    VolatilityRange = (0, 0.35)

    CheckTheSpotPrice= all(SpotPriceRange[0] <= data['Spot-Price']) and all(data['Spot-Price'] <= SpotPriceRange[1])
    CheckTheStrikePrice = all(StrikePriceRange[0] <= data['Strike-Price']) and all(data['Strike-Price'] <= StrikePriceRange[1])
    CheckTheRiskFreeRate = all(RiskFreeRateRange[0] <= data['Risk-Free-Rate']) and all(data['Risk-Free-Rate'] <= RiskFreeRateRange[1])
    CheckTheTime_to_maturity = all(TimeMaturityRange[0] <= data['Time-to-Maturity']) and all(data['Time-to-Maturity'] <= TimeMaturityRange[1])
    CheckTheVolatility= all(VolatilityRange[0] <= data['Volatility']) and all(data['Volatility'] <= VolatilityRange[1])
    return CheckTheSpotPrice and CheckTheStrikePrice and CheckTheRiskFreeRate and CheckTheTime_to_maturity and CheckTheVolatility

np.random.seed(42)
Spot_Price = np.random.uniform(low=0, high=100, size =size_a)
Strike_Price = np.random.uniform(low=20, high=80, size = size_a)
TimeMaturity = np.random.uniform(low=0.04, high=2, size = size_a)
RiskFreeRate = np.random.uniform(low=0, high=0.2, size = size_a)
Volatility = np.random.uniform(low=0, high=0.35, size = size_a)

OptionPrices, NormalD1, NormalD2 = BlackScholes_Call_Price(Spot_Price, Strike_Price, TimeMaturity, RiskFreeRate, Volatility)

data = pd.DataFrame({
    'Spot-Price': Spot_Price,
    'Strike-Price': Strike_Price,
    'Risk-Free-Rate': RiskFreeRate,
    'Time-to-Maturity': TimeMaturity,
    'Volatility': Volatility,
    'Call-Option-Price': OptionPrices,
})

Is_the_data_correct =  Check_Gen_Data(data)

if Is_the_data_correct:
    print("The generated data is within the predefined ranges.")
else:
    print("The generated data is not within the predefined ranges.")


features = data[['Spot-Price', 'Strike-Price', 'Risk-Free-Rate', 'Time-to-Maturity', 'Volatility']]
Data_Target = data['Call-Option-Price']

scaler = MinMaxScaler()

ScaledFeatures = scaler.fit_transform(features)

XTrain, TestX, YTrain, TestY = train_test_split (ScaledFeatures, Data_Target, test_size=0.2, random_state=42)

XTrain_tensor = torch.tensor(XTrain, dtype=torch.float32)
YTrain_tensor = torch.tensor(YTrain.values, dtype=torch.float32).view(-1, 1)

TestX_tensor = torch.tensor(TestX, dtype=torch.float32)
TestY_tensor = torch.tensor(TestY.values, dtype=torch.float32).view(-1, 1)

class BlackScholesNN(nn.Module):
    def __init__(self, Input_Param, Output_param):
        super(BlackScholesNN, self).__init__()
        self.Layer1 = nn.Linear(Input_Param, 150)
        self.relu1 = nn.ReLU()
        self.Layer2 = nn.Linear(150, 100)
        self.relu2 = nn.ReLU()
        self.Layer3 = nn.Linear(100, 80)
        self.relu3 = nn.ReLU()
        self.Layer4 = nn.Linear(80, 60)
        self.relu4 = nn.ReLU()
        self.Layer5 = nn.Linear(60, 40)
        self.relu5 = nn.ReLU()
        self.Layer6 = nn.Linear(40, 20)
        self.relu6 = nn.ReLU()
        self.Layer7 = nn.Linear(20, Output_param)

    def forward(self, x):
        x = self.Layer1(x)
        x = self.relu1(x)
        x = self.Layer2(x)
        x = self.relu2(x)
        x = self.Layer3(x)
        x = self.relu3(x)
        x = self.Layer4(x)
        x = self.relu4(x)
        x = self.Layer5(x)
        x = self.relu5(x)
        x = self.Layer6(x)
        x = self.relu6(x)
        x = self.Layer7(x)
        return x

Input_Param = XTrain_tensor.shape[1]
Output_param = 1

model = BlackScholesNN(Input_Param, Output_param).to(device)

ErrorCriterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001)

Epoch_Size = 2000

for Ep in range(Epoch_Size):
    outputs = model(XTrain_tensor)
    loss = ErrorCriterion(outputs, YTrain_tensor.to(device))

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (Ep + 1) % 100 == 0:
        print(f'Epoch [{Ep+1}/{Epoch_Size}], Loss: {loss.item():.4f}')

with torch.no_grad():
    model.eval()
    all_data_tensor = torch.tensor(ScaledFeatures, dtype=torch.float32).to(device)
    AllThePredictions = model(all_data_tensor)
    test_predictions = model(TestX_tensor.to(device))

MeanSquaredLoss = ErrorCriterion(test_predictions, TestY_tensor).item()

print(f'Mean Squared Error (MSE) on Training Set: {MeanSquaredLoss:.4f}')

AllThePredictionsrelu = torch.relu(AllThePredictions)

if torch.any(AllThePredictionsrelu < 0):
    Random_Coeff = torch.rand_like(AllThePredictionsrelu)
    Tailored_predictions = AllThePredictionsrelu + Random_Coeff * (1 - AllThePredictionsrelu)
else:
    Tailored_predictions = AllThePredictionsrelu

Tailored_predictions_squeezed = Tailored_predictions.numpy().squeeze()

predictions = Tailored_predictions_squeezed.reshape(-1, 1)
AllPredsRelu_Numpy = AllThePredictionsrelu.numpy()

predictions_data = pd.DataFrame({
    'Neural Network Prediction': predictions.flatten()
})

Predictions_Data = pd.concat([data.reset_index(drop=True), pd.DataFrame(AllPredsRelu_Numpy, columns=['Neural Network Prediction'])], axis=1)

Predictions_Data.to_csv('options_fixed.csv', index=False)
Predictions_Data.to_csv('options_fixed.txt', index=False)

Predictions_Data = pd.read_csv('options_fixed.csv')

Predictions_Data['Prediction-Difference'] = Predictions_Data['Neural Network Prediction'] - Predictions_Data['Call-Option-Price']

Average_Diff = Predictions_Data['Prediction-Difference'].mean()
Standard_Deviation = Predictions_Data['Prediction-Difference'].std()

print(f'Average Difference: {Average_Diff:.4f}')
print(f'Standard Deviation: {Standard_Deviation:.4f}')

Predictions_Data['Average Difference'] = Average_Diff
Predictions_Data['Standard Deviation'] = Standard_Deviation
Predictions_Data['Mean Squared Error'] = MeanSquaredLoss

Predictions_Data.to_csv('./option_price_stats_neurons(451)_layers(8)_SGD.csv', index=False)
Predictions_Data.to_csv('./option_price_stats_neurons(451)_layers(8)_SGD.txt', index=False)

plt.figure(figsize=(14, 8))
plt.plot(Predictions_Data.index, Predictions_Data['Call-Option-Price'], label='Actual Option Prices', marker='o')
plt.plot(Predictions_Data.index, Predictions_Data['Neural Network Prediction'], label='Neural Network Predictions', marker='x', color='orange')
plt.title('Project 1. : Actual call option price vs Neural Network Price Predictions - "Expanded" ANN configuration (7 layers 451 neurons) with Adam - 100 data points training dataset', fontsize=10 )
plt.xlabel('Data Points', fontsize=11)
plt.ylabel('Option Prices', fontsize=11)
plt.legend()
plt.savefig('./Line-plot_SGD.pdf')
plt.show()

plt.figure(figsize=(12, 6))
plt.hist(Predictions_Data['Prediction-Difference'], bins=25, color='skyblue', edgecolor='black', density=True)
plt.title('Project 1. : Histogram of options price prediction differences "Expanded" ANN configuration 7 layers 451 neurons with Adam - 100 data points training dataset', fontsize=10)
plt.xlabel('Price prediction difference', fontsize=11)
plt.ylabel('Frequency (Density)', fontsize=11)
plt.savefig('./histogram_SGD.pdf')
plt.show()




import numpy as np
import pandas as pd
from scipy.stats import norm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

import random
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)




def BlackScholes_Call_Price(Spot_Price, Strike_Price, Time_Maturity, Risk_FreeRate, Volatility):
    assert Spot_Price.shape == Strike_Price.shape == Time_Maturity.shape == Risk_FreeRate.shape == Volatility.shape, "Input array shapes do not match"
    D1 = (np.log(Spot_Price/ Strike_Price) + (Risk_FreeRate + 0.5 * Volatility ** 2) * Time_Maturity) / (Volatility * np.sqrt(Time_Maturity))
    D2 = D1 - Volatility * np.sqrt(Time_Maturity)
    NormalD1 = norm.cdf(D1)
    NormalD2 = norm.cdf(D2)
    Call_Price = Spot_Price * NormalD1 - Strike_Price * np.exp(-Risk_FreeRate * Time_Maturity) * NormalD2
    return Call_Price, NormalD1, NormalD2

size__s = 100


def  Check_Gen_Data(data):
    SpotPriceRange = (0, 100)
    StrikePriceRange = (20, 80)
    RiskFreeRateRange = (0, 0.2)
    TimeMaturityRange = (0.04, 2)
    VolatilityRange = (0, 0.35)

    CheckTheSpotPrice= all(SpotPriceRange[0] <= data['Spot-Price']) and all(data['Spot-Price'] <= SpotPriceRange[1])
    CheckTheStrikePrice = all(StrikePriceRange[0] <= data['Strike-Price']) and all(data['Strike-Price'] <= StrikePriceRange[1])
    CheckTheRiskFreeRate = all(RiskFreeRateRange[0] <= data['Risk-Free-Rate']) and all(data['Risk-Free-Rate'] <= RiskFreeRateRange[1])
    CheckTheTime_to_maturity = all(TimeMaturityRange[0] <= data['Time-to-Maturity']) and all(data['Time-to-Maturity'] <= TimeMaturityRange[1])
    CheckTheVolatility= all(VolatilityRange[0] <= data['Volatility']) and all(data['Volatility'] <= VolatilityRange[1])
    return CheckTheSpotPrice and CheckTheStrikePrice and CheckTheRiskFreeRate and CheckTheTime_to_maturity and CheckTheVolatility

np.random.seed(42)
Spot_Price = np.random.uniform(low=0, high=100, size = size__s)
Strike_Price = np.random.uniform(low=20, high=80, size = size__s)
TimeMaturity = np.random.uniform(low=0.04, high=2, size = size__s)
RiskFreeRate = np.random.uniform(low=0, high=0.2, size = size__s)
Volatility = np.random.uniform(low=0, high=0.35, size = size__s)

OptionPrices, NormalD1, NormalD2 = BlackScholes_Call_Price(Spot_Price, Strike_Price, TimeMaturity, RiskFreeRate, Volatility)

data = pd.DataFrame({
    'Spot-Price': Spot_Price,
    'Strike-Price': Strike_Price,
    'Risk-Free-Rate': RiskFreeRate,
    'Time-to-Maturity': TimeMaturity,
    'Volatility': Volatility,
    'Call-Option-Price': OptionPrices,


})

Is_the_data_correct =  Check_Gen_Data(data)

if Is_the_data_correct:
    print("The generated data is within the predefined ranges.")
else:
    print("The generated data is not within the predefined ranges.")

features = data[['Spot-Price', 'Strike-Price', 'Risk-Free-Rate', 'Time-to-Maturity', 'Volatility']]
Data_Target = data['Call-Option-Price']


scaler = MinMaxScaler()

ScaledFeatures = scaler.fit_transform(features)

XTrain, TestX, YTrain, TestY = train_test_split (ScaledFeatures, Data_Target, test_size=0.2, random_state=42)

XTrain_tensor = torch.tensor(XTrain, dtype=torch.float32)
YTrain_tensor = torch.tensor(YTrain.values, dtype=torch.float32).view(-1, 1)

TestX_tensor = torch.tensor(TestX, dtype=torch.float32)


Input_Param = XTrain_tensor.shape[1]
Output_param = 1




class BlackScholesNN(nn.Module):
    def __init__(self, Input_Param, Output_param):
        super(BlackScholesNN, self).__init__()
        self.Layer1 = nn.Linear(Input_Param, 150)
        self.relu1 = nn.ReLU()
        self.Layer2 = nn.Linear(150, 100)
        self.relu2 = nn.ReLU()
        self.Layer3 = nn.Linear(100, 80)
        self.relu3 = nn.ReLU()
        self.Layer4 = nn.Linear(80, 60)
        self.relu4 = nn.ReLU()
        self.Layer5 = nn.Linear(60, 40)
        self.relu5 = nn.ReLU()
        self.Layer6 = nn.Linear(40, 20)
        self.relu6 = nn.ReLU()
        self.Layer7 = nn.Linear(20, Output_param)

    def forward(self, x):
        x = self.Layer1(x)
        x = self.relu1(x)
        x = self.Layer2(x)
        x = self.relu2(x)
        x = self.Layer3(x)
        x = self.relu3(x)
        x = self.Layer4(x)
        x = self.relu4(x)
        x = self.Layer5(x)
        x = self.relu5(x)
        x = self.Layer6(x)
        x = self.relu6(x)
        x = self.Layer7(x)
        return x

model = BlackScholesNN(Input_Param, Output_param)


Number_of_DataPoints_new = 100
np.random.seed(42)

Spot_Prices_For_test = np.random.uniform(low=0, high=100, size=Number_of_DataPoints_new)
Strike_Prices_For_test = np.random.uniform(low=20, high=80, size=Number_of_DataPoints_new)
Risk_FreeRates_For_test = np.random.uniform(low=0, high=0.2, size=Number_of_DataPoints_new)
Time_Maturities__For_test = np.random.uniform(low=0.04, high=2, size=Number_of_DataPoints_new)
VolatilityRanges_For_test = np.random.uniform(low=0, high=0.35, size=Number_of_DataPoints_new)

New_OptionPrices, _, _ = BlackScholes_Call_Price(Spot_Prices_For_test, Strike_Prices_For_test, Time_Maturities__For_test, Risk_FreeRates_For_test, VolatilityRanges_For_test)
DataFrame_For_test= pd.DataFrame({
    'Spot-Price': Spot_Prices_For_test,
    'Strike-Price': Strike_Prices_For_test,
    'Risk-Free-Rate': Risk_FreeRates_For_test,
    'Time-to-Maturity': Time_Maturities__For_test,
    'Volatility': VolatilityRanges_For_test,
    'Call-Option-Price': New_OptionPrices
})

Is_the_data_correct_new = Check_Gen_Data(DataFrame_For_test)

if Is_the_data_correct_new:
    print("Generated new independent testing data is within specified ranges.")
else:
    print("Generated new independent testing data is not within specified ranges.")

features_new = DataFrame_For_test[['Spot-Price', 'Strike-Price', 'Risk-Free-Rate', 'Time-to-Maturity', 'Volatility']]
Data_Target_new = DataFrame_For_test['Call-Option-Price']

ScaledFeatures_new = scaler.transform(features_new)

TestX_tensor_new = torch.tensor(ScaledFeatures_new, dtype=torch.float32)

ErrorCriterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001)

Epoch_Size = 2000

for Ep in range(Epoch_Size):
    outputs = model(XTrain_tensor)
    loss = ErrorCriterion(outputs, YTrain_tensor)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (Ep + 1) % 100 == 0:
        print(f'Epoch [{Ep+1}/{Epoch_Size}], Loss: {loss.item():.4f}')

with torch.no_grad():
    model.eval()
    test_predictions = model(TestX_tensor)



TestPredsRelu = torch.relu(test_predictions)

if torch.any(TestPredsRelu < 0):
    Random_Coeff = torch.rand_like(TestPredsRelu)
    Tailored_predictions = TestPredsRelu + Random_Coeff * (1 - TestPredsRelu)
else:
    Tailored_predictions = TestPredsRelu

Tailored_predictions_squeezed = Tailored_predictions.numpy().squeeze()

predictions_test = Tailored_predictions_squeezed.reshape(-1, 1)
AllNumpyTest = TestPredsRelu.numpy()

predictions_data_test = pd.DataFrame({
    'Neural Network Prediction': predictions_test.flatten()
})

features_new = DataFrame_For_test[['Spot-Price', 'Strike-Price', 'Risk-Free-Rate', 'Time-to-Maturity', 'Volatility']]
Data_Target_new = DataFrame_For_test['Call-Option-Price']

ScaledFeatures_new = scaler.transform(features_new)

TestX_tensor_new = torch.tensor(ScaledFeatures_new, dtype=torch.float32)
test_predictions_new = model(TestX_tensor_new)
test_predictions_newrelu = torch.relu(test_predictions_new)

if torch.any(test_predictions_newrelu < 0):
    Random_Coeff_new = torch.rand_like(test_predictions_newrelu)
    Tailored_predictions_new = test_predictions_newrelu + Random_Coeff_new * (1 - test_predictions_newrelu)
else:
    Tailored_predictions_new = test_predictions_newrelu

Tailored_predictions_squeezed_new = Tailored_predictions_new.detach().numpy().squeeze()

predictions_Test_New = Tailored_predictions_squeezed_new.reshape(-1, 1)
AllNumpyTest_New = Tailored_predictions_squeezed_new.reshape(-1, 1)


predictions_data_Test_New = pd.DataFrame({
    'Neural Network Prediction': predictions_Test_New.flatten()
})

Predictions_Data_Test_New = pd.concat([DataFrame_For_test, pd.DataFrame(AllNumpyTest_New, columns=['Neural Network Prediction'])], axis=1)

Predictions_Data_Test_New['Prediction-Difference'] = Predictions_Data_Test_New['Neural Network Prediction'] - Predictions_Data_Test_New['Call-Option-Price']

Average_Diff_Test = Predictions_Data_Test_New['Prediction-Difference'].mean()
Standard_Deviation_Test = Predictions_Data_Test_New['Prediction-Difference'].std()
MeanSquaredLoss = ((Predictions_Data_Test_New['Prediction-Difference'])**2).mean()



print(f'Average Difference on New Independent Test Set: {Average_Diff_Test:.4f}')
print(f'Standard Deviation on New Independent Test Set: {Standard_Deviation_Test:.4f}')
print(f'Mean Squared Error (MSE) on Testing Set: {MeanSquaredLoss:.4f}')

Predictions_Data_Test_New['Average Difference'] = Average_Diff_Test
Predictions_Data_Test_New['Standard Deviation'] = Standard_Deviation_Test
Predictions_Data_Test_New['Mean Squared Error'] = MeanSquaredLoss


Predictions_Data_Test_New.to_csv('./test_for 100 data points_MeanSquaredLoss.csv', index=False)

plt.figure(figsize=(18, 6))
plt.plot(Predictions_Data_Test_New.index, Predictions_Data_Test_New['Call-Option-Price'], label='Actual Option Prices', marker='o', color='red')
plt.plot(Predictions_Data_Test_New.index, Predictions_Data_Test_New['Neural Network Prediction'], label='Neural Network Predictions', marker='x', color='purple')
plt.title('Project 1. : Actual call option price vs Neural Network Price Predictions - 100 data point independent testing dataset "Expanded" ANN configuration (7 layers 451 neurons) with SGD 1000 data points training dataset', fontsize=10)
plt.xlabel('Data Points')
plt.ylabel('Option Prices')
plt.legend()
plt.savefig('./Line-plot_test_results_new_independent_data for 100 data points.pdf')
plt.show()

plt.figure(figsize=(18, 6))
plt.hist(Predictions_Data_Test_New['Prediction-Difference'], bins=150, color='skyblue', edgecolor='black', density=True)
plt.title('Project 1. : Histogram of options price prediction differences - 100 data point independent testing dataset "Expanded" ANN configuration 7 layers 451 neurons with SGD 1000 data points training dataset',fontsize=10)
plt.xlabel('Prediction-Difference')
plt.ylabel('Frequency (Density)')
plt.savefig('./histogram_test_results_new_independent_data for 100 data points.pdf')
plt.show()

